{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /Users/ericchantland/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "# copy and paste this code in the terminal: huggingface-cli login \n",
    "# then paste this token: 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# It may not show up but still paste the toke in and press enter\n",
    "\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">CULTURE</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"7\" halign=\"left\">ACTION</th>\n",
       "      <th>OTHER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CODER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Passage Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>SubRegion</th>\n",
       "      <th>Culture</th>\n",
       "      <th>DocTitle</th>\n",
       "      <th>Section</th>\n",
       "      <th>Author</th>\n",
       "      <th>Page</th>\n",
       "      <th>Year</th>\n",
       "      <th>OCM</th>\n",
       "      <th>...</th>\n",
       "      <th>Technical_Specialist</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Shaman_Medium_Healer</th>\n",
       "      <th>Priest_High_Religion</th>\n",
       "      <th>Other</th>\n",
       "      <th>Description</th>\n",
       "      <th>Local_terms</th>\n",
       "      <th>Other_Comments</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5153</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>( e )</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>74</td>\n",
       "      <td>1912</td>\n",
       "      <td>['159', '493', '751', '756', '776', '778']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>narrator recalls seing in a dream that by usin...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure how to code this one, misfortune is n...</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5206</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>Untitled Section</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>88</td>\n",
       "      <td>1912</td>\n",
       "      <td>['177', '436', '750', '756', '778', '832']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>injury by Cree medicine can be removed by oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5208</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>Untitled Section</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>90</td>\n",
       "      <td>1912</td>\n",
       "      <td>['177', '609', '753', '755', '761']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>preemptive action: treat all visiting Cree car...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure if \"treating someone carefully\" is co...</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CULTURE                                                \\\n",
       "  Passage Number         Region           SubRegion    Culture   \n",
       "1           5153  North-America  Plains and Plateau  Blackfoot   \n",
       "4           5206  North-America  Plains and Plateau  Blackfoot   \n",
       "5           5208  North-America  Plains and Plateau  Blackfoot   \n",
       "\n",
       "                                                                  \\\n",
       "                                      DocTitle           Section   \n",
       "1  Ceremonial bundles of the Blackfoot Indians             ( e )   \n",
       "4  Ceremonial bundles of the Blackfoot Indians  Untitled Section   \n",
       "5  Ceremonial bundles of the Blackfoot Indians  Untitled Section   \n",
       "\n",
       "                                         \\\n",
       "                      Author Page  Year   \n",
       "1  Wissler, Clark, 1870-1947   74  1912   \n",
       "4  Wissler, Clark, 1870-1947   88  1912   \n",
       "5  Wissler, Clark, 1870-1947   90  1912   \n",
       "\n",
       "                                               ...               ACTION  \\\n",
       "                                          OCM  ... Technical_Specialist   \n",
       "1  ['159', '493', '751', '756', '776', '778']  ...                    0   \n",
       "4  ['177', '436', '750', '756', '778', '832']  ...                    1   \n",
       "5         ['177', '609', '753', '755', '761']  ...                    0   \n",
       "\n",
       "                                                              \\\n",
       "  Divination Shaman_Medium_Healer Priest_High_Religion Other   \n",
       "1          0                    0                    0     0   \n",
       "4          0                    0                    0     0   \n",
       "5          0                    0                    0     1   \n",
       "\n",
       "                                                                  \\\n",
       "                                         Description Local_terms   \n",
       "1  narrator recalls seing in a dream that by usin...           0   \n",
       "4   injury by Cree medicine can be removed by oth...           0   \n",
       "5  preemptive action: treat all visiting Cree car...           0   \n",
       "\n",
       "                                               OTHER    CODER        \n",
       "                                      Other_Comments Finished Coder  \n",
       "1  not sure how to code this one, misfortune is n...     True    AH  \n",
       "4                                                  0     True    AH  \n",
       "5  not sure if \"treating someone carefully\" is co...     True    AH  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../RA_Cleaning/Culture_Coding_old.xlsx\", header=[0,1], index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# subdivide into just passage and outcome\n",
    "df_small = pd.DataFrame()\n",
    "df_small[[\"ID\",\"passage\",\"EVENT\",\"CAUSE\",\"ACTION\"]] = df[[('CULTURE', \"Passage Number\"), ('CULTURE', \"Passage\"), ('EVENT', \"No_Info\"), ('CAUSE', \"No_Info\"), ('ACTION', \"No_Info\")]]\n",
    "# Flip the lable of \"no_info\"\n",
    "df_small[[\"passage\",\"EVENT\",\"CAUSE\",\"ACTION\"]]  = df_small[[\"passage\",\"EVENT\",\"CAUSE\",\"ACTION\"]].replace({0:1, 1:0})\n",
    "\n",
    "\n",
    "# create train and test sets\n",
    "train, test = train_test_split(df_small, test_size=0.2, random_state=10)\n",
    "\n",
    "# Create an NLP friendly dataset\n",
    "Hraf = DatasetDict(\n",
    "    {'train':Dataset.from_dict(train.to_dict(orient= 'list')),\n",
    "     'test':Dataset.from_dict(test.to_dict(orient= 'list'))})\n",
    "Hraf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the training set is as biased as our groups (we want to train on as or less biased data as the groups they come from) <br>\n",
    "We are shooting for .85, .68 and .68 for EVENT, CAUSE, and ACTION respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT: 87.07\n",
      "CAUSE: 69.07\n",
      "ACTION: 67.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_list = [\"EVENT\", \"CAUSE\", \"ACTION\"]\n",
    "for col in col_list:\n",
    "    percentage = round(sum(Hraf['train'][col]) / (len(Hraf['train']))*100,2)\n",
    "    print(f\"{col}: {percentage}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create labels for training and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'EVENT', 1: 'CAUSE', 2: 'ACTION'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = [label for label in Hraf['train'].features.keys() if label not in ['ID', 'passage']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a DistilBERT tokenizer to preprocess the text field: <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERTâ€™s maximum input length:<br>\n",
    "Guidelines were followed from NielsRogge found <a href= \"https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\"> here </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"passage\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, truncation=True) #max length is 512\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "  return encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, use ðŸ¤— Datasets map function. You can speed up map by setting batched=True to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c8c24e5b4c48dda0d7e749ec5426d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4958628d011e4f78a5b4d199c4bf8af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize data, remove all columns and give new ones\n",
    "tokenized_Hraf = Hraf.map(preprocess_data, batched=True, remove_columns=Hraf['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Hraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "[CLS] if some part of the body ( fingers, toes, face, ears ) gets frostbitten ( suvt sayih ), the spot has to be rubbed with snow. during a trip one may also rub the face with snow. i. fellman writes that frostbitten limbs were smeared and rubbed with the heated fat of reindeer cheese. 2 i. f., i, p. 321 ; similarly drake, p. 262. the kolt - lapps smear the frostbitten spot with liquor, mixed with the dried core ( yolk? ) of a goose egg. 3 paulaharju, manuscript. [SEP]\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_Hraf['train'][1]\n",
    "print(example.keys())\n",
    "print(tokenizer.decode(example['input_ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EVENT', 'ACTION']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example['labels'])\n",
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Truncated:  110\n",
      "Percentage Truncated: 7.9%\n",
      "[3, 37, 48, 49, 54, 81, 86, 97, 105, 116, 117, 131, 143, 145, 193, 197, 205, 213, 216, 221, 235, 236, 244, 254, 260, 262, 265, 271, 293, 310, 313, 329, 330, 347, 356, 375, 386, 415, 416, 448, 451, 470, 473, 475, 498, 502, 508, 512, 519, 531, 539, 541, 547, 548, 576, 590, 599, 610, 653, 677, 713, 722, 733, 756, 757, 765, 769, 787, 806, 818, 838, 843, 866, 890, 893, 921, 928, 937, 950, 963, 978, 989, 1008, 1018, 1019, 1032, 1047, 1074, 1081, 1094, 1106, 1112, 1120, 1163, 1181, 1183, 1197, 1211, 1250, 1255, 1256, 1275, 1292, 1297, 1309, 1349, 1351, 1365, 1379, 1381]\n"
     ]
    }
   ],
   "source": [
    "# Number of passages longer than 512 tokens (and therefore truncated)\n",
    "sequence_i = []\n",
    "for i, tx in enumerate(tokenized_Hraf['train']):\n",
    "    if len(tx['input_ids']) == 512:\n",
    "        sequence_i.append(i)\n",
    "print('Number Truncated: ', len(sequence_i))\n",
    "print(f'Percentage Truncated: {round(len(sequence_i)/len(tokenized_Hraf[\"train\"])*100,1)}%')\n",
    "print(sequence_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a batch of examples using <a href=\"https://huggingface.co/docs/transformers/v4.29.0/en/main_classes/data_collator#transformers.DataCollatorWithPadding\"> DataCollatorWithPadding</a>. Itâ€™s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set tokenized passages to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_Hraf.set_format(\"torch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "\n",
    "#     y_pred, y_true = eval_pred\n",
    "#     y_pred = np.argmax(y_pred, axis=1)\n",
    "#     accuracy = accuracy_score(y_pred=y_true, y_true=y_pred)\n",
    "#     f1 = f1_score(y_pred=y_true, y_true=y_pred, average='binary') #binary is the base f1, use 'micro' or 'macro' when you have more than 1 class\n",
    "#     roc_auc = roc_auc_score(y_true, y_pred) #ROC curve\n",
    "#     return  {'accuracy':accuracy, 'f1':f1, 'roc_auc':roc_auc}\n",
    "\n",
    "\n",
    "# # import numpy as np\n",
    "# # from datasets import load_metric\n",
    "\n",
    "# # def compute_metrics(eval_pred):\n",
    "# #     metric = load_metric('accuracy', 'f1')\n",
    "# #     predictions, labels = eval_pred\n",
    "# #     predictions = np.argmax(predictions, axis=1)\n",
    "# #     metric.add_batch(predictions=predictions, references=labels)\n",
    "# #     return  metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Hraf['train'][0]['labels']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train\n",
    "Before you start training your model, create a map of the expected ids to their labels with id2label and label2id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    problem_type='multi_label_classification',\n",
    "    num_labels = len(labels), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7294, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.0433,  0.1309,  0.1214]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass test\n",
    "outputs = model(input_ids=tokenized_Hraf['train']['input_ids'][0].unsqueeze(0), labels=tokenized_Hraf['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"HRAF_Model_MultiLabel_ThreeLargeClasses\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_Hraf[\"train\"],\n",
    "    eval_dataset=tokenized_Hraf[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1400\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 875\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3a0e91447244f0a458ba6d8e02af21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: passage. If passage are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178fe4b91a91496b98b0ecc403a2ef5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.42503783106803894,\n",
       " 'eval_accuracy': 0.8314285714285714,\n",
       " 'eval_f1': 0.8893058161350844,\n",
       " 'eval_roc_auc': 0.7432303471310986,\n",
       " 'eval_runtime': 134.6805,\n",
       " 'eval_samples_per_second': 2.599,\n",
       " 'eval_steps_per_second': 0.163,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967\n",
      "249\n",
      "0.7952302631578947\n"
     ]
    }
   ],
   "source": [
    "print(sum(tokenized_Hraf['train']['label']))\n",
    "print(sum(tokenized_Hraf['test']['label']))\n",
    "print(sum(tokenized_Hraf['train']['label']) / (sum(tokenized_Hraf['test']['label']) + sum(tokenized_Hraf['train']['label'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
