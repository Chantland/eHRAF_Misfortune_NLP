{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4fa2b5f1a8408a8ea01778d0e68a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "# copy and paste this code in the terminal: huggingface-cli login \n",
    "# then paste this token: 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# It may not show up but still paste the toke in and press enter\n",
    "\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">CULTURE</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ACTION</th>\n",
       "      <th>OTHER</th>\n",
       "      <th colspan=\"4\" halign=\"left\">CODER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Passage Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>SubRegion</th>\n",
       "      <th>Culture</th>\n",
       "      <th>DocTitle</th>\n",
       "      <th>Section</th>\n",
       "      <th>Author</th>\n",
       "      <th>Page</th>\n",
       "      <th>Year</th>\n",
       "      <th>OCM</th>\n",
       "      <th>...</th>\n",
       "      <th>Shaman_Medium_Healer</th>\n",
       "      <th>Priest_High_Religion</th>\n",
       "      <th>Other</th>\n",
       "      <th>Description</th>\n",
       "      <th>Local_terms</th>\n",
       "      <th>Other_Comments</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>EC NOTES (not in python)</th>\n",
       "      <th>EC NOTES (not in python).1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5153</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>( e )</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>74</td>\n",
       "      <td>1912</td>\n",
       "      <td>['159', '493', '751', '756', '776', '778']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>narrator recalls seing in a dream that by usin...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure how to code this one, misfortune is n...</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5206</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>Untitled Section</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>88</td>\n",
       "      <td>1912</td>\n",
       "      <td>['177', '436', '750', '756', '778', '832']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>injury by Cree medicine can be removed by oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5208</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>Untitled Section</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>90</td>\n",
       "      <td>1912</td>\n",
       "      <td>['177', '609', '753', '755', '761']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>preemptive action: treat all visiting Cree car...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure if \"treating someone carefully\" is co...</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CULTURE                                                \\\n",
       "  Passage Number         Region           SubRegion    Culture   \n",
       "1           5153  North-America  Plains and Plateau  Blackfoot   \n",
       "4           5206  North-America  Plains and Plateau  Blackfoot   \n",
       "5           5208  North-America  Plains and Plateau  Blackfoot   \n",
       "\n",
       "                                                                  \\\n",
       "                                      DocTitle           Section   \n",
       "1  Ceremonial bundles of the Blackfoot Indians             ( e )   \n",
       "4  Ceremonial bundles of the Blackfoot Indians  Untitled Section   \n",
       "5  Ceremonial bundles of the Blackfoot Indians  Untitled Section   \n",
       "\n",
       "                                         \\\n",
       "                      Author Page  Year   \n",
       "1  Wissler, Clark, 1870-1947   74  1912   \n",
       "4  Wissler, Clark, 1870-1947   88  1912   \n",
       "5  Wissler, Clark, 1870-1947   90  1912   \n",
       "\n",
       "                                               ...               ACTION  \\\n",
       "                                          OCM  ... Shaman_Medium_Healer   \n",
       "1  ['159', '493', '751', '756', '776', '778']  ...                    0   \n",
       "4  ['177', '436', '750', '756', '778', '832']  ...                    0   \n",
       "5         ['177', '609', '753', '755', '761']  ...                    0   \n",
       "\n",
       "                              \\\n",
       "  Priest_High_Religion Other   \n",
       "1                    0     0   \n",
       "4                    0     0   \n",
       "5                    0     1   \n",
       "\n",
       "                                                                  \\\n",
       "                                         Description Local_terms   \n",
       "1  narrator recalls seing in a dream that by usin...           0   \n",
       "4   injury by Cree medicine can be removed by oth...           0   \n",
       "5  preemptive action: treat all visiting Cree car...           0   \n",
       "\n",
       "                                               OTHER    CODER        \\\n",
       "                                      Other_Comments Finished Coder   \n",
       "1  not sure how to code this one, misfortune is n...     True    AH   \n",
       "4                                                  0     True    AH   \n",
       "5  not sure if \"treating someone carefully\" is co...     True    AH   \n",
       "\n",
       "                                                       \n",
       "  EC NOTES (not in python) EC NOTES (not in python).1  \n",
       "1                      NaN                        NaN  \n",
       "4                      NaN                        NaN  \n",
       "5                      NaN                        NaN  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../RA_Cleaning/Culture_Coding_old.xlsx\", header=[0,1], index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CULTURE', 'Passage Number'),\n",
       " ('CULTURE', 'Passage'),\n",
       " ('EVENT', 'No_Info'),\n",
       " ('EVENT', 'Illness'),\n",
       " ('EVENT', 'Accident'),\n",
       " ('EVENT', 'Other'),\n",
       " ('CAUSE', 'No_Info'),\n",
       " ('CAUSE', 'Just_Happens'),\n",
       " ('CAUSE', 'Material_Physical'),\n",
       " ('CAUSE', 'Spirits_Gods'),\n",
       " ('CAUSE', 'Witchcraft_Sorcery'),\n",
       " ('CAUSE', 'Rule_Violation_Taboo'),\n",
       " ('CAUSE', 'Jealousy_Evil_Eye'),\n",
       " ('ACTION', 'No_Info'),\n",
       " ('ACTION', 'Physical_Material'),\n",
       " ('ACTION', 'Technical_Specialist'),\n",
       " ('ACTION', 'Divination'),\n",
       " ('ACTION', 'Shaman_Medium_Healer'),\n",
       " ('ACTION', 'Priest_High_Religion'),\n",
       " ('ACTION', 'Other')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "id_index = cols.index(('CULTURE', \"Passage Number\"))\n",
    "passage_index = cols.index(('CULTURE', \"Passage\"))\n",
    "event_index =  cols.index(('EVENT', \"No_Info\"))\n",
    "cause_index = cols.index(('CAUSE', \"No_Info\"))\n",
    "action_index = cols.index(('ACTION', \"No_Info\"))\n",
    "# get a list of all the multi-indexed column names we want to evaluate\n",
    "col_list = [cols[id_index]] + [cols[passage_index]] + cols[event_index:event_index+4] + cols[cause_index:cause_index+7] + cols[action_index:action_index+7]\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'passage',\n",
       " 'EVENT',\n",
       " 'EVENT_Illness',\n",
       " 'EVENT_Accident',\n",
       " 'EVENT_Other',\n",
       " 'CAUSE',\n",
       " 'CAUSE_Just_Happens',\n",
       " 'CAUSE_Material_Physical',\n",
       " 'CAUSE_Spirits_Gods',\n",
       " 'CAUSE_Witchcraft_Sorcery',\n",
       " 'CAUSE_Rule_Violation_Taboo',\n",
       " 'CAUSE_Jealousy_Evil_Eye',\n",
       " 'ACTION',\n",
       " 'ACTION_Physical_Material',\n",
       " 'ACTION_Technical_Specialist',\n",
       " 'ACTION_Divination',\n",
       " 'ACTION_Shaman_Medium_Healer',\n",
       " 'ACTION_Priest_High_Religion',\n",
       " 'ACTION_Other']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get column names to ascribe to the new data frame\n",
    "colNames = [\"ID\",\"passage\"]\n",
    "for category, sub_cat in col_list:\n",
    "    # skip passage and id which have already been added\n",
    "    # print(category, sub_cat)\n",
    "    if category == \"CULTURE\":\n",
    "        continue\n",
    "    \n",
    "    if sub_cat == \"No_Info\":\n",
    "        colNames += [category]\n",
    "    else:\n",
    "        colNames += [f'{category}_{sub_cat}']\n",
    "colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'EVENT_Illness', 'EVENT_Accident', 'EVENT_Other', 'CAUSE', 'CAUSE_Just_Happens', 'CAUSE_Material_Physical', 'CAUSE_Spirits_Gods', 'CAUSE_Witchcraft_Sorcery', 'CAUSE_Rule_Violation_Taboo', 'CAUSE_Jealousy_Evil_Eye', 'ACTION', 'ACTION_Physical_Material', 'ACTION_Technical_Specialist', 'ACTION_Divination', 'ACTION_Shaman_Medium_Healer', 'ACTION_Priest_High_Religion', 'ACTION_Other'],\n",
       "        num_rows: 1396\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'EVENT_Illness', 'EVENT_Accident', 'EVENT_Other', 'CAUSE', 'CAUSE_Just_Happens', 'CAUSE_Material_Physical', 'CAUSE_Spirits_Gods', 'CAUSE_Witchcraft_Sorcery', 'CAUSE_Rule_Violation_Taboo', 'CAUSE_Jealousy_Evil_Eye', 'ACTION', 'ACTION_Physical_Material', 'ACTION_Technical_Specialist', 'ACTION_Divination', 'ACTION_Shaman_Medium_Healer', 'ACTION_Priest_High_Religion', 'ACTION_Other'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# subdivide into just passage and outcome\n",
    "df_small = pd.DataFrame()\n",
    "df_small[colNames] = df[col_list]\n",
    "# Flip the lable of \"no_info\"\n",
    "df_small[[\"EVENT\",\"CAUSE\",\"ACTION\"]]  = df_small[[\"EVENT\",\"CAUSE\",\"ACTION\"]].replace({0:1, 1:0})\n",
    "\n",
    "# Remove certain passages which should not be in training or inference (these are duplicates that had to be manually found by a human)\n",
    "values_to_remove = [3252, 33681, 6758, 10104]\n",
    "df_small = df_small[~df_small['ID'].isin(values_to_remove)]\n",
    "df_small\n",
    "\n",
    "\n",
    "# create train and test sets\n",
    "train, test = train_test_split(df_small, test_size=0.2, random_state=10)\n",
    "\n",
    "# Create an NLP friendly dataset\n",
    "Hraf = DatasetDict(\n",
    "    {'train':Dataset.from_dict(train.to_dict(orient= 'list')),\n",
    "     'test':Dataset.from_dict(test.to_dict(orient= 'list'))})\n",
    "Hraf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the training set is as biased as our groups (we want to train on as or less biased data as the groups they come from) <br>\n",
    "We are shooting for .85, .68 and .68 for EVENT, CAUSE, and ACTION respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT: 86.46\n",
      "EVENT_Illness: 66.91\n",
      "EVENT_Accident: 7.88\n",
      "EVENT_Other: 25.14\n",
      "CAUSE: 69.56\n",
      "CAUSE_Just_Happens: 5.3\n",
      "CAUSE_Material_Physical: 25.21\n",
      "CAUSE_Spirits_Gods: 36.32\n",
      "CAUSE_Witchcraft_Sorcery: 12.25\n",
      "CAUSE_Rule_Violation_Taboo: 11.17\n",
      "CAUSE_Jealousy_Evil_Eye: 3.08\n",
      "ACTION: 68.27\n",
      "ACTION_Physical_Material: 40.04\n",
      "ACTION_Technical_Specialist: 8.09\n",
      "ACTION_Divination: 6.09\n",
      "ACTION_Shaman_Medium_Healer: 17.55\n",
      "ACTION_Priest_High_Religion: 3.37\n",
      "ACTION_Other: 14.54\n"
     ]
    }
   ],
   "source": [
    "# print bias per label\n",
    "labels = [label for label in Hraf['train'].features.keys() if label not in ['ID', 'passage']]\n",
    "for col in labels:\n",
    "    percentage = round(sum(Hraf['train'][col]) / (len(Hraf['train']))*100,2)\n",
    "    print(f\"{col}: {percentage}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create labels for training and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'EVENT',\n",
       " 1: 'EVENT_Illness',\n",
       " 2: 'EVENT_Accident',\n",
       " 3: 'EVENT_Other',\n",
       " 4: 'CAUSE',\n",
       " 5: 'CAUSE_Just_Happens',\n",
       " 6: 'CAUSE_Material_Physical',\n",
       " 7: 'CAUSE_Spirits_Gods',\n",
       " 8: 'CAUSE_Witchcraft_Sorcery',\n",
       " 9: 'CAUSE_Rule_Violation_Taboo',\n",
       " 10: 'CAUSE_Jealousy_Evil_Eye',\n",
       " 11: 'ACTION',\n",
       " 12: 'ACTION_Physical_Material',\n",
       " 13: 'ACTION_Technical_Specialist',\n",
       " 14: 'ACTION_Divination',\n",
       " 15: 'ACTION_Shaman_Medium_Healer',\n",
       " 16: 'ACTION_Priest_High_Religion',\n",
       " 17: 'ACTION_Other'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = [label for label in Hraf['train'].features.keys() if label not in ['ID', 'passage']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a DistilBERT tokenizer to preprocess the text field: <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERT’s maximum input length:<br>\n",
    "Guidelines were followed from NielsRogge found <a href= \"https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\"> here </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"passage\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, truncation=True) #max length is 512\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "  return encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, use 🤗 Datasets map function. You can speed up map by setting batched=True to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f19d96540954318b06d77c04be3c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1396 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70630556f9c4f7c83ecbd2bd7e64dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize data, remove all columns and give new ones\n",
    "tokenized_Hraf = Hraf.map(preprocess_data, batched=True, remove_columns=Hraf['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1396\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Hraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "[CLS] if some part of the body ( fingers, toes, face, ears ) gets frostbitten ( suvt sayih ), the spot has to be rubbed with snow. during a trip one may also rub the face with snow. i. fellman writes that frostbitten limbs were smeared and rubbed with the heated fat of reindeer cheese. 2 i. f., i, p. 321 ; similarly drake, p. 262. the kolt - lapps smear the frostbitten spot with liquor, mixed with the dried core ( yolk? ) of a goose egg. 3 paulaharju, manuscript. [SEP]\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_Hraf['train'][1]\n",
    "print(example.keys())\n",
    "print(tokenizer.decode(example['input_ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EVENT', 'EVENT_Illness', 'ACTION', 'ACTION_Physical_Material']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example['labels'])\n",
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Truncated:  113\n",
      "Percentage Truncated: 8.1%\n",
      "[3, 7, 8, 37, 49, 65, 81, 83, 88, 94, 97, 116, 117, 130, 131, 145, 151, 163, 192, 197, 216, 230, 236, 242, 244, 254, 255, 260, 265, 271, 293, 310, 336, 339, 343, 356, 370, 378, 386, 397, 412, 415, 419, 451, 456, 466, 470, 477, 504, 505, 512, 526, 535, 539, 541, 576, 581, 584, 599, 653, 666, 689, 694, 701, 703, 756, 757, 768, 769, 778, 787, 789, 806, 824, 835, 843, 846, 850, 858, 866, 890, 898, 928, 937, 963, 1006, 1032, 1073, 1095, 1110, 1112, 1128, 1148, 1153, 1162, 1181, 1189, 1213, 1227, 1254, 1273, 1274, 1280, 1290, 1307, 1345, 1347, 1355, 1356, 1361, 1375, 1377, 1391]\n"
     ]
    }
   ],
   "source": [
    "# Number of passages longer than 512 tokens (and therefore truncated)\n",
    "sequence_i = []\n",
    "for i, tx in enumerate(tokenized_Hraf['train']):\n",
    "    if len(tx['input_ids']) == 512:\n",
    "        sequence_i.append(i)\n",
    "print('Number Truncated: ', len(sequence_i))\n",
    "print(f'Percentage Truncated: {round(len(sequence_i)/len(tokenized_Hraf[\"train\"])*100,1)}%')\n",
    "print(sequence_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a batch of examples using <a href=\"https://huggingface.co/docs/transformers/v4.29.0/en/main_classes/data_collator#transformers.DataCollatorWithPadding\"> DataCollatorWithPadding</a>. It’s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set tokenized passages to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_Hraf.set_format(\"torch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "\n",
    "#     y_pred, y_true = eval_pred\n",
    "#     y_pred = np.argmax(y_pred, axis=1)\n",
    "#     accuracy = accuracy_score(y_pred=y_true, y_true=y_pred)\n",
    "#     f1 = f1_score(y_pred=y_true, y_true=y_pred, average='binary') #binary is the base f1, use 'micro' or 'macro' when you have more than 1 class\n",
    "#     roc_auc = roc_auc_score(y_true, y_pred) #ROC curve\n",
    "#     return  {'accuracy':accuracy, 'f1':f1, 'roc_auc':roc_auc}\n",
    "\n",
    "\n",
    "# # import numpy as np\n",
    "# # from datasets import load_metric\n",
    "\n",
    "# # def compute_metrics(eval_pred):\n",
    "# #     metric = load_metric('accuracy', 'f1')\n",
    "# #     predictions, labels = eval_pred\n",
    "# #     predictions = np.argmax(predictions, axis=1)\n",
    "# #     metric.add_batch(predictions=predictions, references=labels)\n",
    "# #     return  metric.compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain F1 score for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Hraf['train'][0]['labels']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train\n",
    "Before you start training your model, create a map of the expected ids to their labels with id2label and label2id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    problem_type='multi_label_classification',\n",
    "    num_labels = len(labels), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6782, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.0747, -0.0342, -0.0867,  0.0379, -0.0070, -0.0222,  0.0260, -0.0259,\n",
       "         -0.0831,  0.0762, -0.0469, -0.0643, -0.1154, -0.0404,  0.0387,  0.0493,\n",
       "         -0.0710, -0.1142]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass test\n",
    "outputs = model(input_ids=tokenized_Hraf['train']['input_ids'][0].unsqueeze(0), labels=tokenized_Hraf['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"HRAF_Model_MultiLabel_SubClasses\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_Hraf[\"train\"],\n",
    "    eval_dataset=tokenized_Hraf[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1396\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 875\n",
      "  Number of trainable parameters = 66967314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2c8172d894476192206dd13be4aee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9568426377054a9dbddb82ebb9c0c9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_SubClasses/checkpoint-175\n",
      "Configuration saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-175/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41065430641174316, 'eval_f1': 0.667278849097031, 'eval_roc_auc': 0.7616334780182695, 'eval_accuracy': 0.0, 'eval_runtime': 107.1579, 'eval_samples_per_second': 3.266, 'eval_steps_per_second': 0.411, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-175/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-175/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-175/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30412c2cfdce45c9aec8653923e40340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_SubClasses/checkpoint-350\n",
      "Configuration saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-350/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38348057866096497, 'eval_f1': 0.692448233861145, 'eval_roc_auc': 0.7780945131452475, 'eval_accuracy': 0.002857142857142857, 'eval_runtime': 90.7152, 'eval_samples_per_second': 3.858, 'eval_steps_per_second': 0.485, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-350/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4077, 'learning_rate': 8.571428571428571e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63e0a4fe4984564bc253e2408c92b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_SubClasses/checkpoint-525\n",
      "Configuration saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-525/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3677811026573181, 'eval_f1': 0.7051744885679904, 'eval_roc_auc': 0.7873223134208052, 'eval_accuracy': 0.022857142857142857, 'eval_runtime': 90.6425, 'eval_samples_per_second': 3.861, 'eval_steps_per_second': 0.485, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-525/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-525/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-525/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2977f235f1a74b9788f47233c80a5a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_SubClasses/checkpoint-700\n",
      "Configuration saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35647499561309814, 'eval_f1': 0.7114503816793892, 'eval_roc_auc': 0.7900212002732531, 'eval_accuracy': 0.04857142857142857, 'eval_runtime': 90.64, 'eval_samples_per_second': 3.861, 'eval_steps_per_second': 0.485, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-700/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e951b622b234f05b3905803494706a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_SubClasses/checkpoint-875\n",
      "Configuration saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-875/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3486453592777252, 'eval_f1': 0.7183271832718328, 'eval_roc_auc': 0.7937415018923373, 'eval_accuracy': 0.05142857142857143, 'eval_runtime': 90.5252, 'eval_samples_per_second': 3.866, 'eval_steps_per_second': 0.486, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-875/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-875/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_SubClasses/checkpoint-875/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_SubClasses/checkpoint-875 (score: 0.7183271832718328).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6761.4168, 'train_samples_per_second': 1.032, 'train_steps_per_second': 0.129, 'train_loss': 0.3710736607142857, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=875, training_loss=0.3710736607142857, metrics={'train_runtime': 6761.4168, 'train_samples_per_second': 1.032, 'train_steps_per_second': 0.129, 'train_loss': 0.3710736607142857, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a2fa628bbb4a2bacf2999310561b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3486453592777252,\n",
       " 'eval_f1': 0.7183271832718328,\n",
       " 'eval_roc_auc': 0.7937415018923373,\n",
       " 'eval_accuracy': 0.05142857142857143,\n",
       " 'eval_runtime': 95.2372,\n",
       " 'eval_samples_per_second': 3.675,\n",
       " 'eval_steps_per_second': 0.462,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"If one falls sick or dies, the natives at once conclude he must have been bewitched, or bitten, or hurt by the devil-- eringa .\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n",
    "\n",
    "Next, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT', 'EVENT_Illness', 'CAUSE', 'CAUSE_Spirits_Gods']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.5)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
