{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /Users/ericchantland/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "# copy and paste this code in the terminal: huggingface-cli login \n",
    "# then paste this token: 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# It may not show up but still paste the toke in and press enter\n",
    "\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">CULTURE</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"7\" halign=\"left\">ACTION</th>\n",
       "      <th>OTHER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CODER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Passage Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>SubRegion</th>\n",
       "      <th>Culture</th>\n",
       "      <th>DocTitle</th>\n",
       "      <th>Section</th>\n",
       "      <th>Author</th>\n",
       "      <th>Page</th>\n",
       "      <th>Year</th>\n",
       "      <th>OCM</th>\n",
       "      <th>...</th>\n",
       "      <th>Technical_Specialist</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Shaman_Medium_Healer</th>\n",
       "      <th>Priest_High_Religion</th>\n",
       "      <th>Other</th>\n",
       "      <th>Description</th>\n",
       "      <th>Local_terms</th>\n",
       "      <th>Other_Comments</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5153</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>( e )</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>74</td>\n",
       "      <td>1912</td>\n",
       "      <td>['159', '493', '751', '756', '776', '778']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>narrator recalls seing in a dream that by usin...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure how to code this one, misfortune is n...</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5206</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>Untitled Section</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>88</td>\n",
       "      <td>1912</td>\n",
       "      <td>['177', '436', '750', '756', '778', '832']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>injury by Cree medicine can be removed by oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5208</td>\n",
       "      <td>North-America</td>\n",
       "      <td>Plains and Plateau</td>\n",
       "      <td>Blackfoot</td>\n",
       "      <td>Ceremonial bundles of the Blackfoot Indians</td>\n",
       "      <td>Untitled Section</td>\n",
       "      <td>Wissler, Clark, 1870-1947</td>\n",
       "      <td>90</td>\n",
       "      <td>1912</td>\n",
       "      <td>['177', '609', '753', '755', '761']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>preemptive action: treat all visiting Cree car...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure if \"treating someone carefully\" is co...</td>\n",
       "      <td>True</td>\n",
       "      <td>AH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CULTURE                                                \\\n",
       "  Passage Number         Region           SubRegion    Culture   \n",
       "1           5153  North-America  Plains and Plateau  Blackfoot   \n",
       "4           5206  North-America  Plains and Plateau  Blackfoot   \n",
       "5           5208  North-America  Plains and Plateau  Blackfoot   \n",
       "\n",
       "                                                                  \\\n",
       "                                      DocTitle           Section   \n",
       "1  Ceremonial bundles of the Blackfoot Indians             ( e )   \n",
       "4  Ceremonial bundles of the Blackfoot Indians  Untitled Section   \n",
       "5  Ceremonial bundles of the Blackfoot Indians  Untitled Section   \n",
       "\n",
       "                                         \\\n",
       "                      Author Page  Year   \n",
       "1  Wissler, Clark, 1870-1947   74  1912   \n",
       "4  Wissler, Clark, 1870-1947   88  1912   \n",
       "5  Wissler, Clark, 1870-1947   90  1912   \n",
       "\n",
       "                                               ...               ACTION  \\\n",
       "                                          OCM  ... Technical_Specialist   \n",
       "1  ['159', '493', '751', '756', '776', '778']  ...                    0   \n",
       "4  ['177', '436', '750', '756', '778', '832']  ...                    1   \n",
       "5         ['177', '609', '753', '755', '761']  ...                    0   \n",
       "\n",
       "                                                              \\\n",
       "  Divination Shaman_Medium_Healer Priest_High_Religion Other   \n",
       "1          0                    0                    0     0   \n",
       "4          0                    0                    0     0   \n",
       "5          0                    0                    0     1   \n",
       "\n",
       "                                                                  \\\n",
       "                                         Description Local_terms   \n",
       "1  narrator recalls seing in a dream that by usin...           0   \n",
       "4   injury by Cree medicine can be removed by oth...           0   \n",
       "5  preemptive action: treat all visiting Cree car...           0   \n",
       "\n",
       "                                               OTHER    CODER        \n",
       "                                      Other_Comments Finished Coder  \n",
       "1  not sure how to code this one, misfortune is n...     True    AH  \n",
       "4                                                  0     True    AH  \n",
       "5  not sure if \"treating someone carefully\" is co...     True    AH  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../RA_Cleaning/Culture_Coding.xlsx\", header=[0,1], index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['passage', 'label'],\n",
       "        num_rows: 1460\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['passage', 'label'],\n",
       "        num_rows: 365\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# subdivide into just passage and outcome\n",
    "df_small = pd.DataFrame()\n",
    "df_small[[\"passage\",\"label\"]] = df[[('CULTURE', \"Passage\"), ('EVENT', \"No_Info\")]]\n",
    "# Flip the lable of \"no_info\"\n",
    "df_small[\"label\"] = df_small['label'].replace({0:1, 1:0})\n",
    "\n",
    "\n",
    "# create train and test sets\n",
    "train, test = train_test_split(df_small, test_size=0.2, random_state=10)\n",
    "\n",
    "# Create an NLP friendly dataset\n",
    "Hraf = DatasetDict(\n",
    "    {'train':Dataset.from_dict(train.to_dict(orient= 'list')),\n",
    "     'test':Dataset.from_dict(test.to_dict(orient= 'list'))})\n",
    "Hraf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import collections\n",
    "\n",
    "print(inspect.signature(train_test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Amulets. Amulets (Nsiriba) may be distinguished from fetiches (Mayembe), in that the former seldom possessed supernatural powers, but were used chiefly for medicinal purposes. They were carried or worn on the person to be ready for use; some of them were in fact turned into ornaments, and carried about long after they had ceased to be required for their original purpose. The medicine-men were the vendors of amulets; the majority were composed either of wood or of herbs, made into compact shapes by the medicine-men, so that they could be carried about on the person. Some of them were for outward application only; others were to be taken internally; they were rubbed on a stone or scraped with a knife, and the powder thus obtained was mixed with water or beer, if for internal use, and with butter, if for FIG. 51.â€”AMULETS. outward application. They had a wide range as remedies; indeed, almost every ailment known to the medicine-men was treated with some kind of amulet. The expectant mother had her amulet, and the person suffering from inflammation of the eyes had his. These amulets were valued so highly by the people that, when the disease was healed, the medicine was not cast aside, but decorated and worn as an ornament, and was thus ready, should there be any return of the old symptoms. As charms they were used chiefly for the prevention of disease; their medicinal properties had brought them into notoriety, and they were afterwards regarded as possessing powers to avert the evil which they had originally been meant to cure. One amulet partook of the nature of a fetich, it was called Luzalo, and was designed to insure fecundity. It consisted of a piece of wood, often sewn into a small cat-skin bag, at times decorated with cowry-shells, and worn tied round the waist, so that the amulet rested in front of the wearer. Other amulets having the same purpose were small packets of powdered herbs, which were worn by the woman round her waist; some of the powder would be mixed with water, and drunk from time to time. These packets of herbs were not called nsiriba, like other amulets, but lukisa .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hraf['train'][0]['passage']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a DistilBERT tokenizer to preprocess the text field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERTâ€™s maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"passage\"], truncation=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, use ðŸ¤— Datasets map function. You can speed up map by setting batched=True to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc68ab9979d04ee8bb348b03b8093aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5044fd59d74014b8c36020f404fa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_Hraf = Hraf.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['passage', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['passage', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Hraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "[12, 26, 31, 34, 39, 48, 49, 89, 109, 113, 118, 157, 159, 167, 202, 207, 208, 223, 224, 226, 227, 238, 241, 245, 255, 270, 288, 290, 293, 318, 326, 333, 343]\n"
     ]
    }
   ],
   "source": [
    "# Number of passages longer than 512 tokens\n",
    "phrase = []\n",
    "sequence_i = []\n",
    "for i, tx in enumerate(tokenized_Hraf['test']):\n",
    "    if len(tx['input_ids']) == 512:\n",
    "        phrase.append(tx['passage'])\n",
    "        sequence_i.append(i)\n",
    "print(len(phrase))\n",
    "print(sequence_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a batch of examples using <a href=\"https://huggingface.co/docs/transformers/v4.29.0/en/main_classes/data_collator#transformers.DataCollatorWithPadding\"> DataCollatorWithPadding</a>. Itâ€™s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train\n",
    "Before you start training your model, create a map of the expected ids to their labels with id2label and label2id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"ABSENT\", 1: \"PRESENT\"}\n",
    "label2id = {\"ABSENT\": 0, \"PRESENT\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: passage. If passage are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1400\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 352\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b49de2412974496a6de9daf5a43a837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: passage. If passage are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1057578806eb4894b449b15173ec4bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Demo/checkpoint-88\n",
      "Configuration saved in HRAF_Demo/checkpoint-88/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30423155426979065, 'eval_accuracy': 0.8742857142857143, 'eval_runtime': 113.5781, 'eval_samples_per_second': 3.082, 'eval_steps_per_second': 0.194, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Demo/checkpoint-88/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Demo/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Demo/checkpoint-88/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: passage. If passage are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019cf09a6b234028a166c1e6e17ab485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Demo/checkpoint-176\n",
      "Configuration saved in HRAF_Demo/checkpoint-176/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3032442033290863, 'eval_accuracy': 0.8914285714285715, 'eval_runtime': 113.9396, 'eval_samples_per_second': 3.072, 'eval_steps_per_second': 0.193, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Demo/checkpoint-176/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Demo/checkpoint-176/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Demo/checkpoint-176/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: passage. If passage are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08738a3cf51a4f54881c3b73fc11f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Demo/checkpoint-264\n",
      "Configuration saved in HRAF_Demo/checkpoint-264/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2552239000797272, 'eval_accuracy': 0.8971428571428571, 'eval_runtime': 113.3372, 'eval_samples_per_second': 3.088, 'eval_steps_per_second': 0.194, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Demo/checkpoint-264/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Demo/checkpoint-264/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Demo/checkpoint-264/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: passage. If passage are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 350\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbede25eacb4e0ab6e7ff82acb65503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Demo/checkpoint-352\n",
      "Configuration saved in HRAF_Demo/checkpoint-352/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2677306830883026, 'eval_accuracy': 0.9, 'eval_runtime': 113.3799, 'eval_samples_per_second': 3.087, 'eval_steps_per_second': 0.194, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Demo/checkpoint-352/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Demo/checkpoint-352/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Demo/checkpoint-352/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Demo/checkpoint-264 (score: 0.2552239000797272).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6227.829, 'train_samples_per_second': 0.899, 'train_steps_per_second': 0.057, 'train_loss': 0.23678220402110706, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=352, training_loss=0.23678220402110706, metrics={'train_runtime': 6227.829, 'train_samples_per_second': 0.899, 'train_steps_per_second': 0.057, 'train_loss': 0.23678220402110706, 'epoch': 4.0})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"HRAF_Demo\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_Hraf[\"train\"],\n",
    "    eval_dataset=tokenized_Hraf[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
