{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code simply seeks to do one thing, compare accuracy of simple lexical search to the more complicated NLP model <br>\n",
    "The code will leverage the idential code in \"N-Grams_Multilable.ipynb\" to make its classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you must have a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE What model is desired to be used\n",
    "model = \"HRAF_MultiLabel_ThreeLargeClasses_kfoldsDEMO\"\n",
    "# CHANGE Path to model datasets  (you may not need to chnage this)\n",
    "path = f\"../HRAF_NLP/{model}\"\n",
    "# CHANGE Folder\n",
    "folder = \"Datasets\"\n",
    "# CHANGE column name used for passages (typically it is passages but this is to future proof)\n",
    "passColName = \"passage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading Json into datasets\n",
    "def load_json(path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    dataset = datasets.Dataset.from_dict(data)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passage_list = [line['passage'] for line in test]\n",
    "# passage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset partitions, run only one of these code chunks and comment out the rest\n",
    "\n",
    "\n",
    "# # pre-split training, validation and test datasets\n",
    "# train = load_json(path=f\"{path}/{folder}/train_dataset.json\")\n",
    "# validation = load_json(path=f\"{path}/{folder}/validation_dataset.json\")\n",
    "# test = load_json(path=f\"{path}/{folder}/test_dataset.json\")\n",
    "# train = datasets.concatenate_datasets([train, validation]) # combine both train and validation\n",
    "# labels = [label for label in train.features.keys() if label not in ['ID', passColName]]\n",
    "\n",
    "\n",
    "\n",
    "# pre-split training and test datasets (train contains both train and validation)\n",
    "train = load_json(path=f\"{path}/{folder}/train_dataset.json\")\n",
    "test = load_json(path=f\"{path}/{folder}/test_dataset.json\")\n",
    "labels = [label for label in train.features.keys() if label not in ['ID', passColName]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Full dataset that requires splitting after the fact (NOT READY YET)\n",
    "# with open(f\"{path}/tokenized_inputs.json\") as f:\n",
    "#     all = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram functions (run them all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import time\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "def N_gram_creator(text:list, ngram:int, delete_stopwords:bool=False, use_end_tokens:bool=False, fuse_ngrams:bool=True):\n",
    "\n",
    "    # whether or not to include end tokens inside the datasets\n",
    "    if use_end_tokens == True:\n",
    "        start = text.count(\"[CLS]\") + 1\n",
    "        end = text.count(\"[SEP]\") + 1\n",
    "        assert start == end, \"Unequal number of start and end tokens\"\n",
    "        if start < ngram:\n",
    "            text = ['[CLS]'] * (ngram- start) + text + ['[SEP]'] * (ngram- end)\n",
    "            start = text.count(\"[CLS]\") + 1\n",
    "            end = text.count(\"[SEP]\") + 1\n",
    "        temp=zip(*[text[i+(start-ngram):(len(text)-(end-ngram))] for i in range(0,ngram)]) #zip a set of \"n\" Ngrams. disregard \"[sep]\" depending on the NGram number.\n",
    "    else:\n",
    "        # create Ngram by zipping\n",
    "        temp=zip(*[text[i:] for i in range(0,ngram)])\n",
    "    ans=[list(ngram) for ngram in temp]\n",
    "\n",
    "    # delete all ngrams that contain stopwords (after the fact creation of Ngrams)\n",
    "    if delete_stopwords == True:\n",
    "        ngram_buffer = []\n",
    "        cached_stopwords = set(stopwords.words('english'))\n",
    "        for ngram in ans:\n",
    "            if not bool(cached_stopwords.intersection(ngram)):\n",
    "                ngram_buffer.append(ngram)\n",
    "        ans = ngram_buffer\n",
    "    # delete all ngrams that start or end with stop words (per https://stats.stackexchange.com/questions/570698/should-i-remove-stopwords-before-generating-n-grams)\n",
    "    elif delete_stopwords == 'ends':\n",
    "        ngram_buffer = []\n",
    "        for ngram in ans:\n",
    "            if (ngram[0] not in set(stopwords.words('english')) and ngram[-1] not in set(stopwords.words('english'))):\n",
    "                ngram_buffer.append(ngram)\n",
    "        ans = ngram_buffer\n",
    "\n",
    "    # Optionally turn to string\n",
    "    if fuse_ngrams:\n",
    "        ans = [' '.join(ngram) for ngram in ans]\n",
    "    return ans\n",
    "\n",
    "def N_gram_dictionary(passage_dict_list_copy, ngram_num:int, label:str, passagefreq:bool=True, use_end_tokens:bool=False, use_tokenized:bool=False, tokenizer=False, text_name:str='passage', id_name:str='ID', predLabel_name:str='pred_labels', actualLabel_name:str='actual_labels'): #must be a dictionary containing passages as an input\n",
    "    \"\"\"\n",
    "    Create a dataframe composed of specified Ngram and label\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    passage_dict_list_copy : list of dictionaries containing text for Ngrams, predicted labels, and actual labels. Typically derived from machine learning model\n",
    "    ngram_num : int, ngram number\n",
    "    label : string, label used for Ngram\n",
    "    passagefreq : boolean, should it count the frequency of passages occuring?\n",
    "    use_end_tokens : boolean, should we include end tokens like [CLS] as ngrams?\n",
    "    use_tokenized : boolean, is the dataframe already tokenized\n",
    "    tokenizer : NLP tokenizer, you must supply what that tokenizer is!\n",
    "    text_name : string, column name of text used for Ngrams\n",
    "    id_name : string, column name of IDs\n",
    "    predLabel_name : string, column name of predicted label\n",
    "    actualLabel_name : string, column name of actual label\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Ngram_dict : list of dictionaries containing Ngrams and their frequencies\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_tokenized is True:\n",
    "        assert tokenizer is not False, \"Must supply a tokenizer\"\n",
    "\n",
    "    Ngram_dict = dict()\n",
    "    passage_dict_list = copy.deepcopy(passage_dict_list_copy)\n",
    "    # get Ngrams and assign frequencies\n",
    "    for passage_dict in passage_dict_list:\n",
    "        # return tokenized (and cleaned) passage\n",
    "        if use_tokenized is True:\n",
    "            passage_dict['t_words'] = list(itemgetter(*passage_dict['input_ids'])(tokenizer))\n",
    "            passage_dict['t_words'] = [passage_dict['t_words'][0]] + passage_dict['t_words'] + [passage_dict['t_words'][-1]]\n",
    "        else:\n",
    "            passage_dict['t_words'] = tokenize_words(passage_dict[text_name])\n",
    "\n",
    "        Ngram_passage_count = set() # refresh set for checking if an Ngram has appeared in a passage\n",
    "        # Create NGrams and assign frequencies\n",
    "        for word in N_gram_creator(passage_dict['t_words'], ngram_num, use_end_tokens):\n",
    "            # set up the dictionary for that word \n",
    "            # (frequency is the number of times the Ngram has appeared in total, _pred refers to the model prediction of negative or positive, _actual refers to the RA label;\n",
    "            # percentage is positive count divided by frequency, passage_frequency refers to the number of passages the Ngram has appeared where duplicates in a passage are not counted)\n",
    "            if word not in Ngram_dict.keys():\n",
    "                if passagefreq is True: # count passage frequency\n",
    "                    Ngram_dict[word] = {'Frequency':0, 'Neg_pred':0,  'Neg_actual':0, \"Pos_pred\":0, \"Pos_actual\":0, \"Percentage_pred\":0, \"Percentage_actual\":0, \"Passage_freq\":0, \"passage_ID\":set()}\n",
    "                else: # don't count passage frequency\n",
    "                    Ngram_dict[word] = {'Frequency':0, 'Neg_pred':0,  'Neg_actual':0, \"Pos_pred\":0, \"Pos_actual\":0, \"Percentage_pred\":0, \"Percentage_actual\":0} \n",
    "            Ngram_dict[word]['Frequency'] += 1\n",
    "\n",
    "            # assign frequency if the Ngram has not already appeared in the passage.\n",
    "            if passagefreq is True and word not in Ngram_passage_count:\n",
    "                Ngram_passage_count.add(word)\n",
    "                Ngram_dict[word]['Passage_freq'] += 1\n",
    "                Ngram_dict[word]['passage_ID'].add(passage_dict[id_name])\n",
    "\n",
    "\n",
    "            # Get predicted count\n",
    "            if passage_dict[predLabel_name][label] == 0:\n",
    "                Ngram_dict[word]['Neg_pred'] += 1\n",
    "            elif passage_dict[predLabel_name][label] == 1:\n",
    "                Ngram_dict[word]['Pos_pred'] += 1\n",
    "            else:\n",
    "                raise ValueError\n",
    "            \n",
    "            # Get actual count\n",
    "            if passage_dict[actualLabel_name][label] == 0:\n",
    "                Ngram_dict[word]['Neg_actual'] += 1\n",
    "            elif passage_dict[actualLabel_name][label] == 1:\n",
    "                Ngram_dict[word]['Pos_actual'] += 1\n",
    "            else:\n",
    "                raise ValueError\n",
    "    # assign percentage (positves/total)\n",
    "    for Ngram in Ngram_dict.keys():\n",
    "        Ngram_dict[Ngram]['Percentage_pred'] = Ngram_dict[Ngram]['Pos_pred']/  Ngram_dict[Ngram]['Frequency']\n",
    "        Ngram_dict[Ngram]['Percentage_actual'] = Ngram_dict[Ngram]['Pos_actual']/  Ngram_dict[Ngram]['Frequency']\n",
    "    \n",
    "    return Ngram_dict\n",
    "\n",
    "\n",
    "def tokenize_words(passage:str, removeStopWords=True):\n",
    "    passage = passage.lower() #lower case everything\n",
    "    passage = re.sub(r'\\.\\.\\.', ' ', passage) # replace elipsis with ' '\n",
    "    passage_t = passage.split(\" \") # get tokens (note that nltk.word_tokenize may be a better option but it messes with non-english text too much)\n",
    "    \n",
    "    \n",
    "    # clean up punctuation, remove all but .!? which will become their own token\n",
    "    word_list = []\n",
    "    for word in passage_t:\n",
    "        # optional remove stopwords\n",
    "        punctEnd_list = []\n",
    "        # remove punct from the start of words (some odd punctuation needed to be added).\n",
    "        safety_count = 0 #include safety count to break in case the file runs too long\n",
    "        punct = string.punctuation+'—‘’“”'\n",
    "        while (len(word) > 0) and word[0] in punct:\n",
    "            if word[0] in '?!.':\n",
    "                word_list += word[0]\n",
    "            word = word[1:]\n",
    "            safety_count += 1\n",
    "            assert safety_count<1000\n",
    "        # remove punct from the end of words\n",
    "        while (len(word) > 0) and word[-1] in punct:\n",
    "            if word[-1] in '?!.':\n",
    "                punctEnd_list += word[-1]\n",
    "            word = word[:-1]\n",
    "            safety_count += 1\n",
    "            assert safety_count<1000\n",
    "        # append if there is something to add.\n",
    "        if len(word) > 0:\n",
    "            word_list += [word]\n",
    "        if len(punctEnd_list) >0:\n",
    "            word_list += punctEnd_list\n",
    "    if removeStopWords is True: \n",
    "        cached_stopwords = set(stopwords.words('english'))\n",
    "        word_list = [word for word in word_list if word not in cached_stopwords]\n",
    "    passage_t = word_list\n",
    "    return passage_t\n",
    "\n",
    "# Save the NGram dictionary\n",
    "def saveFile(dictionary, fileName, folder, frequency_cutoff=5):\n",
    "    make_dir(folder)\n",
    "    df2 = pd.DataFrame.from_dict(dictionary, orient='index')\n",
    "    df2.insert(0, 'N-gram', df2.index)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    df2 = df2.sort_values(by=['Pos_pred'], ascending=False) \n",
    "    # drop all frequencies 5 or less (to shorten the file)\n",
    "    df2 = df2.loc[df2['Frequency']>=frequency_cutoff]\n",
    "\n",
    "    df2.to_excel(f'{folder}/{fileName}', index=False)\n",
    "    return fileName + ' Complete'\n",
    "\n",
    "# made directory\n",
    "def make_dir(path):\n",
    "    import os\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "        os.makedirs(path)\n",
    "        \n",
    "# only needs \"actual labels\" and text, spits out pandas dataframe for frequency\n",
    "def ngram_frequency_creator(passages:list, label_list:list, ngram_num:int, tokenized_input:bool = False, frequency_cutoff:int=5, percentage_cutoff:float=False):\n",
    "    assert isinstance(passages, list), \"ERROR passage Input must be a list of passages\"\n",
    "    # get tokens and then get ngrams from those tokens\n",
    "    if tokenized_input == False: # does your input need to be tokenized?\n",
    "        assert ~isinstance(passages[0], list), \"ERROR Your Passage list input appears to be a list of lists, are you sure you didn't mean to select tokenized_input = True?\"\n",
    "        tokenizedWords_list = [tokenize_words(passage) for passage in passages]\n",
    "    else:\n",
    "        tokenizedWords_list = passages\n",
    "    NgramTokens_list = [N_gram_creator(tokenizedWords, ngram_num) for tokenizedWords in tokenizedWords_list]\n",
    "    # get dictionary of Ngram frequency and actual label\n",
    "    Ngram_dict = dict()\n",
    "    for index, NgramTokens in enumerate(NgramTokens_list):\n",
    "        for word in NgramTokens:\n",
    "            if word not in Ngram_dict.keys():\n",
    "                Ngram_dict[word] = {'Frequency':0, 'Neg_actual':0, \"Pos_actual\":0, \"Percentage_actual\":0} \n",
    "            Ngram_dict[word]['Frequency'] += 1\n",
    "\n",
    "            # Get actual count\n",
    "            if label_list[index] == 0:\n",
    "                Ngram_dict[word]['Neg_actual'] += 1\n",
    "            elif label_list[index] == 1:\n",
    "                Ngram_dict[word]['Pos_actual'] += 1\n",
    "            else:\n",
    "                raise ValueError\n",
    "    # assign percentage (positves/total)\n",
    "    for Ngram in Ngram_dict.keys():\n",
    "        Ngram_dict[Ngram]['Percentage_actual'] = Ngram_dict[Ngram]['Pos_actual']/  Ngram_dict[Ngram]['Frequency']\n",
    "    \n",
    "    # create dataframe and remove those below cutoff\n",
    "    df2 = pd.DataFrame.from_dict(Ngram_dict, orient='index')\n",
    "    df2.insert(0, 'N-gram', df2.index)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    # drop all frequencies that are too small\n",
    "    df2 = df2.loc[df2['Frequency']>=frequency_cutoff]\n",
    "\n",
    "    # delete those with too small frequencies\n",
    "    if percentage_cutoff:\n",
    "        df2 = df2.loc[df2['Percentage_actual']>=percentage_cutoff]\n",
    "    \n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Lexical Search via Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_F1</th>\n",
       "      <th>CAUSE_F1</th>\n",
       "      <th>ACTION_F1</th>\n",
       "      <th>Micro_F1</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ngram Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             EVENT_F1 CAUSE_F1 ACTION_F1 Micro_F1 Macro_F1\n",
       "Ngram Number                                              \n",
       "1                0.82    0.738     0.656     0.75    0.553\n",
       "2               0.759    0.606     0.547    0.658    0.407\n",
       "3               0.122     0.05     0.085     0.09    0.038"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHANGE: give a list of N-gram INTEGERS you want to extract (typically [1,2,3] is a good choice )\n",
    "Ngram_nums = [1,2,3] \n",
    "# CHANGE: percentage cutoff in decimal of NGrams with positive rating (i.e. only use Ngrams that are in positively labeled passages x% of the time), You may also put False as a viable input\n",
    "percentage_cutoff = .85\n",
    "# CHANGE: choose the frequency an Ngram must appear in general to be allowed to be part of the list ( you do not want to use Ngrams that only appear a single time in the whole dataset)\n",
    "frequency_cutoff = 5 \n",
    "\n",
    "df_scores = pd.DataFrame(index = Ngram_nums, columns= [label+\"_F1\" for label in labels] + [\"Micro_F1\", \"Macro_F1\"] )\n",
    "df_scores.index.name = 'Ngram Number' \n",
    "\n",
    "# tokenize the training and test sets first to save on time\n",
    "trainPass_T = [tokenize_words(passage) for passage in train[passColName]]\n",
    "testPass_T = [tokenize_words(passage) for passage in test[passColName]]\n",
    "\n",
    "\n",
    "\n",
    "for Ngram_num in Ngram_nums:\n",
    "    predictLabels_list = []\n",
    "    actualLabels_list = []\n",
    "    for label in labels:\n",
    "        #extract 'target' Ngrams from training dataset\n",
    "        passage_list = trainPass_T\n",
    "        label_list = train[label]\n",
    "        df_trainTargets = ngram_frequency_creator(passages=passage_list, label_list=label_list, ngram_num=Ngram_num, tokenized_input=True, frequency_cutoff=frequency_cutoff, percentage_cutoff=percentage_cutoff)\n",
    "        if len(df_trainTargets) == 0:\n",
    "            print(f'No Ngrams for {Ngram_num} using {label}')\n",
    "            continue\n",
    "        targetNgrams_set = set(df_trainTargets['N-gram']) #get only the Ngrams from the result as these will be what we use to predict\n",
    "\n",
    "\n",
    "        # Predict present or absent based on if target Ngrams appear in the passage (which is also turned into Ngrams)\n",
    "        testNgrams = [N_gram_creator(tokenizedWords, Ngram_num) for tokenizedWords in testPass_T] # get all the ngrams, technically we could use ngram_frequency_creator() instead since it uses this exact line but this way we skip the superfluous frequency counting!\n",
    "        predictLabels = [0 if set(PassageNgrams).isdisjoint(targetNgrams_set) else 1 for PassageNgrams in testNgrams] # predict 0 if none of a particular test passage's Ngrams are in the train target Ngrams other wise predict 1\n",
    "        actualLabels = test[label]\n",
    "        \n",
    "        # Get F1 score for label x Ngram\n",
    "        df_scores.at[Ngram_num, f\"{label}_F1\"] = round(f1_score(y_true=actualLabels, y_pred=predictLabels),3)\n",
    "\n",
    "        # Save predictions and actual for later F1 micro and macro\n",
    "        predictLabels_list.append(predictLabels)\n",
    "        actualLabels_list.append(actualLabels)\n",
    "\n",
    "    #F1 micro and macro score for all the labels\n",
    "    df_scores.at[Ngram_num, \"Micro_F1\"] = round(f1_score(y_true=actualLabels_list, y_pred=predictLabels_list, average='micro'),3)\n",
    "    df_scores.at[Ngram_num, \"Macro_F1\"]  = round(f1_score(y_true=actualLabels_list, y_pred=predictLabels_list, average='macro'),3)\n",
    "df_scores = df_scores.astype(\"Float32\")\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model (using F1 micro) 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_F1</th>\n",
       "      <th>CAUSE_F1</th>\n",
       "      <th>ACTION_F1</th>\n",
       "      <th>Micro_F1</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical search</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                EVENT_F1  CAUSE_F1  ACTION_F1  Micro_F1  Macro_F1\n",
       "Lexical search      0.82     0.738      0.656      0.75     0.553"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show and set up the best model \n",
    "largest_idx = df_scores['Micro_F1'].idxmax()\n",
    "df_score = df_scores.loc[[largest_idx]].copy()\n",
    "df_score.rename(index={largest_idx: \"Lexical search\"}, inplace=True)\n",
    "df_score.index.name = None\n",
    "print(f\"best model (using F1 micro) {largest_idx}\")\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>EVENT_F1</th>\n",
       "      <th>CAUSE_F1</th>\n",
       "      <th>ACTION_F1</th>\n",
       "      <th>Micro_F1</th>\n",
       "      <th>Macro_F1</th>\n",
       "      <th>test_length</th>\n",
       "      <th>train_length</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical search</th>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.553</td>\n",
       "      <td>728</td>\n",
       "      <td>2910</td>\n",
       "      <td>Ngram 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP</th>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.809</td>\n",
       "      <td>728</td>\n",
       "      <td>2910</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  EVENT_F1  CAUSE_F1  ACTION_F1  Micro_F1  Macro_F1   \n",
       "Lexical search 2024-02-02      0.82     0.738      0.656      0.75     0.553  \\\n",
       "NLP            2024-02-02     0.883     0.812      0.733     0.816     0.809   \n",
       "\n",
       "                test_length  train_length    Notes  \n",
       "Lexical search          728          2910  Ngram 1  \n",
       "NLP                     728          2910        -  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save prediciton data\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# export F1 scores to excel\n",
    "df_scoresSep = df_score.copy()\n",
    "# first load train (and maybe add validation)\n",
    "train = load_json(path=f\"{path}/{folder}/train_dataset.json\")\n",
    "\n",
    "if os.path.isfile(path=f\"{path}/{folder}/validation_dataset.json\"):\n",
    "    valid = load_json(path=f\"{path}/{folder}/validation_dataset.json\")\n",
    "    train = datasets.concatenate_datasets([train, valid])\n",
    "# add lengths of test and training set\n",
    "df_scoresSep[[\"test_length\", \"train_length\"]] = (len(test), len(train))\n",
    "# add date\n",
    "df_scoresSep.insert(0, \"Date\", [datetime.today().date()])\n",
    "#add optional notes (for Ngrams)\n",
    "df_scoresSep['Notes'] = f\"Ngram {largest_idx}\"\n",
    "# load model_performance.xlsx or else create it\n",
    "if os.path.isfile(f\"{path}/Model_Prediction_Performance.xlsx\"):\n",
    "    df_oldScores = pd.read_excel(f\"{path}/Model_Prediction_Performance.xlsx\", index_col=0)\n",
    "    df_oldScores_merged = pd.concat([df_scoresSep, df_oldScores])\n",
    "    nonDateCols = df_oldScores_merged.columns[df_scoresSep.columns != 'Date']\n",
    "    if any(df_oldScores_merged.duplicated(subset=nonDateCols)): # don't append the data unless it is new\n",
    "        print(\"Duplicated scores found, skipping new addition\")\n",
    "        df_scoresSep = df_oldScores.copy()\n",
    "    else:\n",
    "        df_scoresSep = df_oldScores_merged.copy()\n",
    "        df_scoresSep['Date'] = df_scoresSep['Date'].astype('datetime64[ns]')\n",
    "        df_scoresSep.to_excel(f\"{path}/Model_Prediction_Performance.xlsx\")\n",
    "else:\n",
    "    df_scoresSep['Date'] = df_scoresSep['Date'].astype('datetime64[ns]')\n",
    "    df_scoresSep.to_excel(f\"{path}/Model_Prediction_Performance.xlsx\")\n",
    "\n",
    "df_scoresSep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 0 1 1 1 0]\n",
      " [0 1 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 1 1 0 0 1 1 0]]\n",
      "[[1 1 0 1 0 0 0 1 1 0]\n",
      " [1 1 0 1 0 0 0 1 1 0]\n",
      " [0 1 0 1 1 0 0 0 1 0]]\n",
      "0.49333333333333335\n",
      "1.0 0.625\n",
      "0.6 1.0\n",
      "1.0 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "# DELETE, this is a test for the zero-division warning seen above.\n",
    "dummmy_predict = np.array(predictLabels_list)[:,0:10]\n",
    "print(dummmy_predict)\n",
    "dummmy_actual = np.array(actualLabels_list)[:,0:10]\n",
    "print(dummmy_actual)\n",
    "\n",
    "print(f1_score(y_true=dummmy_actual, y_pred=dummmy_predict, average='macro'))\n",
    "for predict, actual in zip(dummmy_predict, dummmy_actual):\n",
    "    recall = recall_score(y_true=actual, y_pred=predict)\n",
    "    prec = precision_score(y_true=actual, y_pred=predict)\n",
    "    print(recall, prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
