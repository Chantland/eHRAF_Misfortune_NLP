{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "import evaluate\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26d19ed679845068be65ce4158dd616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OPTIONAL IF YOU WANT TO PUSH TO THE HUB!\n",
    "from huggingface_hub import notebook_login\n",
    "# IF RUNNING THIS CELL DOES NOT WORK:\n",
    "# copy and paste this code in the terminal: huggingface-cli login \n",
    "# then paste this token: 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# It may not show up but still paste the token in and press enter\n",
    "\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">CULTURE</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ACTION</th>\n",
       "      <th>OTHER</th>\n",
       "      <th colspan=\"5\" halign=\"left\">CODER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Passage Number</th>\n",
       "      <th>Region</th>\n",
       "      <th>SubRegion</th>\n",
       "      <th>Culture</th>\n",
       "      <th>DocTitle</th>\n",
       "      <th>Section</th>\n",
       "      <th>Author</th>\n",
       "      <th>Page</th>\n",
       "      <th>Year</th>\n",
       "      <th>OCM</th>\n",
       "      <th>...</th>\n",
       "      <th>Priest_High_Religion</th>\n",
       "      <th>Other</th>\n",
       "      <th>Description</th>\n",
       "      <th>Local_terms</th>\n",
       "      <th>Other_Comments</th>\n",
       "      <th>Run_Number</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1392</td>\n",
       "      <td>Asia</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Andamans</td>\n",
       "      <td>Hygiene and medical practices among the Onge (...</td>\n",
       "      <td>1. Habitation</td>\n",
       "      <td>Cipriani, Lidio</td>\n",
       "      <td>484</td>\n",
       "      <td>1961</td>\n",
       "      <td>['171', '301', '727', '751', '765', '775', '777']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Several customs are believed to connect with t...</td>\n",
       "      <td>ibidanghe: made from decorated human jawbone ...</td>\n",
       "      <td>General note of this spreadsheet - many of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>YM</td>\n",
       "      <td>1</td>\n",
       "      <td>Dataset 1: ['750', '751', '752', '753']   Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>Asia</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Andamans</td>\n",
       "      <td>Hygiene and medical practices among the Onge (...</td>\n",
       "      <td>3. Food</td>\n",
       "      <td>Cipriani, Lidio</td>\n",
       "      <td>487</td>\n",
       "      <td>1961</td>\n",
       "      <td>['136', '231', '271', '312', '415', '516', '751']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No action is mentioned</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>YM</td>\n",
       "      <td>1</td>\n",
       "      <td>Dataset 2: ['784', '731', '732', '777', '791',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1395</td>\n",
       "      <td>Asia</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Andamans</td>\n",
       "      <td>Hygiene and medical practices among the Onge (...</td>\n",
       "      <td>3. Food</td>\n",
       "      <td>Cipriani, Lidio</td>\n",
       "      <td>490</td>\n",
       "      <td>1961</td>\n",
       "      <td>['114', '137', '164', '262', '273', '751', '825']</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Certain foods, such as Pteropus (giant bat) an...</td>\n",
       "      <td>Pteropus: a giant bat  eaten by the Andaman Is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>YM</td>\n",
       "      <td>1</td>\n",
       "      <td>Run 1: Spring 2023 Coding of Sickness dataset ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CULTURE                               \\\n",
       "  Passage Number Region   SubRegion   Culture   \n",
       "0           1392   Asia  South Asia  Andamans   \n",
       "1           1393   Asia  South Asia  Andamans   \n",
       "2           1395   Asia  South Asia  Andamans   \n",
       "\n",
       "                                                                     \\\n",
       "                                            DocTitle        Section   \n",
       "0  Hygiene and medical practices among the Onge (...  1. Habitation   \n",
       "1  Hygiene and medical practices among the Onge (...        3. Food   \n",
       "2  Hygiene and medical practices among the Onge (...        3. Food   \n",
       "\n",
       "                               \\\n",
       "            Author Page  Year   \n",
       "0  Cipriani, Lidio  484  1961   \n",
       "1  Cipriani, Lidio  487  1961   \n",
       "2  Cipriani, Lidio  490  1961   \n",
       "\n",
       "                                                      ...  \\\n",
       "                                                 OCM  ...   \n",
       "0  ['171', '301', '727', '751', '765', '775', '777']  ...   \n",
       "1  ['136', '231', '271', '312', '415', '516', '751']  ...   \n",
       "2  ['114', '137', '164', '262', '273', '751', '825']  ...   \n",
       "\n",
       "                ACTION        \\\n",
       "  Priest_High_Religion Other   \n",
       "0                    0     1   \n",
       "1                    0     0   \n",
       "2                    0     0   \n",
       "\n",
       "                                                      \\\n",
       "                                         Description   \n",
       "0  Several customs are believed to connect with t...   \n",
       "1                             No action is mentioned   \n",
       "2  Certain foods, such as Pteropus (giant bat) an...   \n",
       "\n",
       "                                                      \\\n",
       "                                         Local_terms   \n",
       "0   ibidanghe: made from decorated human jawbone ...   \n",
       "1                                                  0   \n",
       "2  Pteropus: a giant bat  eaten by the Andaman Is...   \n",
       "\n",
       "                                               OTHER      CODER           \\\n",
       "                                      Other_Comments Run_Number Finished   \n",
       "0  General note of this spreadsheet - many of the...          1     True   \n",
       "1                                                NaN          1     True   \n",
       "2                                                NaN          1     True   \n",
       "\n",
       "                                                                    \n",
       "  Coder Dataset                                               Info  \n",
       "0    YM       1  Dataset 1: ['750', '751', '752', '753']   Coun...  \n",
       "1    YM       1  Dataset 2: ['784', '731', '732', '777', '791',...  \n",
       "2    YM       1  Run 1: Spring 2023 Coding of Sickness dataset ...  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../../eHRAF_Scraper-Analysis-and-Prep/Data/\"\n",
    "dataFolder = r\"(subjects-(contracts_OR_disabilities_OR_disasters_OR_friendships_OR_gift_giving_OR_infant_feeding_OR_lineages_OR_local_officials_OR_luck_and_chance_OR_magicians_and_diviners_OR_mortuary_specialists_OR_nuclear_family_OR_priesthood_OR_prophet/\"\n",
    "# dataFolder = r'subjects-(sickness)_FILTERS-culture_level_samples(PSF)'\n",
    "\n",
    "#load df (only load one of these commented out lines)\n",
    "# df = pd.read_excel(f\"{path}{dataFolder}/_Altogether_Dataset_RACoded.xlsx\", header=[0,1], index_col=0) # Fall 2023 sickness + non-sickness\n",
    "df = pd.read_excel(f\"{path}{dataFolder}/_Altogether_Dataset_RACoded_Combined.xlsx\", header=[0,1], index_col=0) # Spring 2023 - Spring 2024  sickness + nonsickness dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run_Number  Dataset\n",
       "1           1          1926\n",
       "2           1            51\n",
       "3           1          4193\n",
       "            2          3305\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CODER\"][[\"Run_Number\", \"Dataset\"]].value_counts(sort=False, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 7578\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 1895\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# subdivide into just passage and outcome\n",
    "df_small = pd.DataFrame()\n",
    "df_small[[\"ID\",\"passage\",\"EVENT\",\"CAUSE\",\"ACTION\"]] = df[[('CULTURE', \"Passage Number\"), ('CULTURE', \"Passage\"), ('EVENT', \"No_Info\"), ('CAUSE', \"No_Info\"), ('ACTION', \"No_Info\")]]\n",
    "# Flip the lable of \"no_info\"\n",
    "df_small[[\"EVENT\",\"CAUSE\",\"ACTION\"]]  = df_small[[\"EVENT\",\"CAUSE\",\"ACTION\"]].replace({0:1, 1:0})\n",
    "\n",
    "# Remove certain passages which should not be in training or inference (these are duplicates that had to be manually found by a human)\n",
    "values_to_remove = [3252, 33681, 6758, 10104]\n",
    "df_small = df_small[~df_small['ID'].isin(values_to_remove)]\n",
    "\n",
    "df_small\n",
    "\n",
    "# # create train and validation/test sets\n",
    "# train_val, test = train_test_split(df_small, test_size=0.2, random_state=10)\n",
    "\n",
    "# create train and validation/test sets\n",
    "train_val, test = train_test_split(df_small, test_size=0.2, random_state=10)\n",
    "# # do it again to get the test and validation sets (15% = 50% * 30%)\n",
    "# test, validation = train_test_split(test_val, test_size=0.5, random_state=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an NLP friendly dataset\n",
    "Hraf = DatasetDict(\n",
    "    {'train':Dataset.from_dict(train_val.to_dict(orient= 'list')),\n",
    "     'test':Dataset.from_dict(test.to_dict(orient= 'list'))})\n",
    "Hraf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the training set is as biased as our groups (we want to train on as or less biased data as the groups they come from) <br>\n",
    "We are shooting for equivelent biases across test, train, and validation (if it exists at this step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                TOTAL     train     test\n",
      "____________________________________________________________\n",
      "EVENT:                          65.41     65.47     65.17     \n",
      "CAUSE:                          48.87     49.26     47.28     \n",
      "ACTION:                         49.74     49.72     49.82     \n"
     ]
    }
   ],
   "source": [
    "# extract the total proportion\n",
    "def totalProportion(df, col, present=1):\n",
    "    value_counts = df[col].value_counts()\n",
    "    percentage = round(value_counts[present]/len(df)*100,2)\n",
    "    return percentage\n",
    "\n",
    "# extracts percentages per datafaframe\n",
    "def colProportion(Hraf, col):\n",
    "    percentage_list = []\n",
    "    for dataframe in Hraf.keys():\n",
    "        percentage_list += [round(sum(Hraf[dataframe][col]) / (len(Hraf[dataframe]))*100,2)]\n",
    "    return percentage_list\n",
    "\n",
    "\n",
    "\n",
    "# print bias per label\n",
    "dataframe_keys= Hraf.keys()\n",
    "labels = [label for label in Hraf['train'].features.keys() if label not in ['ID', 'passage']]\n",
    "header = \"                                TOTAL\"\n",
    "for key in dataframe_keys:\n",
    "    header += f\"     {key}\"\n",
    "print(header)\n",
    "print('_'*(len(header)+4))\n",
    "for col in labels:\n",
    "    totalPercentage =  totalProportion(df_small, col)\n",
    "    percentage_list =  colProportion(Hraf, col)\n",
    "    spacing = 10\n",
    "    percentage_str = f\"{totalPercentage}{' '* (spacing-len(str(totalPercentage)))}\"\n",
    "    for index, key in enumerate(dataframe_keys):\n",
    "        percentage_str += f\"{(len(key)-5)*' '}{percentage_list[index]}{' '* (spacing-len(str(percentage_list[index])))}\"\n",
    "    print(f\"{col}:{' ' * (30- len(col))} {percentage_str}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create labels for training and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'EVENT', 1: 'CAUSE', 2: 'ACTION'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = [label for label in Hraf['train'].features.keys() if label not in ['ID', 'passage']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a DistilBERT tokenizer to preprocess the text field: <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERT’s maximum input length:<br>\n",
    "Guidelines were followed from NielsRogge found <a href= \"https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\"> here </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"passage\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, max_length=512, truncation=True) #max length for BERT is 512\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "  return encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, use 🤗 Datasets map function. You can speed up map by setting batched=True to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eb423f36f04567985102a7cdeb1274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd88895d74104691a7d3c93e5b4d7377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 7578\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1895\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize data, remove all columns and give new ones\n",
    "tokenized_Hraf = Hraf.map(preprocess_data, batched=True, remove_columns=Hraf['train'].column_names)\n",
    "tokenized_Hraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "[CLS] the religion has certainly operated to discourage scientific investigation and the progress of arts and technology. for example : the ifugao ’ s medical knowledge is little more than nil and lies principally in the setting of broken bones and the reduction of dislocations. the art descends from ancestor to son or, in some cases, daughter. some of the bone - setters do a fairly good job of opposing the ends of fractures. i was once talking to a young practitioner, a bright enough fellow by natural endowment, but a conservative in the art. he belittled the art of bone manipulation : “ the prayer is the important thing, ” he said, “ the prayer and the sacrifice. if these be right, the recovery will be right. ” [SEP]\n"
     ]
    }
   ],
   "source": [
    "# sample decoding\n",
    "example = tokenized_Hraf['train'][1]\n",
    "print(example.keys())\n",
    "print(tokenizer.decode(example['input_ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EVENT', 'ACTION']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example['labels'])\n",
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Truncated:  151\n",
      "Percentage Truncated: 2.0%\n",
      "[24, 42, 75, 129, 256, 267, 284, 307, 405, 487, 493, 517, 586, 673, 689, 804, 853, 902, 925, 933, 980, 988, 1017, 1063, 1102, 1272, 1289, 1344, 1392, 1440, 1539, 1551, 1556, 1719, 1885, 1886, 1915, 1965, 2013, 2069, 2228, 2254, 2356, 2384, 2422, 2498, 2501, 2548, 2632, 2860, 2866, 2888, 2918, 2935, 3120, 3123, 3177, 3499, 3607, 3805, 3808, 3859, 3868, 3875, 3891, 3894, 3909, 3963, 3969, 4054, 4072, 4108, 4163, 4194, 4258, 4392, 4402, 4430, 4476, 4479, 4480, 4491, 4562, 4739, 4779, 4874, 4896, 4937, 4961, 4968, 5008, 5025, 5033, 5059, 5068, 5156, 5164, 5176, 5189, 5316, 5373, 5389, 5413, 5414, 5439, 5526, 5546, 5578, 5579, 5615, 5653, 5704, 5720, 5791, 5823, 5840, 5903, 5952, 5996, 6144, 6147, 6158, 6173, 6211, 6251, 6252, 6419, 6514, 6571, 6647, 6661, 6682, 6702, 6743, 6828, 6890, 6975, 6995, 6996, 7027, 7049, 7098, 7105, 7166, 7200, 7215, 7308, 7407, 7410, 7499, 7539]\n"
     ]
    }
   ],
   "source": [
    "# Number of passages longer than 512 tokens (and therefore truncated)\n",
    "sequence_i = []\n",
    "for i, tx in enumerate(tokenized_Hraf['train']):\n",
    "    if len(tx['input_ids']) >= 512:\n",
    "        sequence_i.append(i)\n",
    "print('Number Truncated: ', len(sequence_i))\n",
    "print(f'Percentage Truncated: {round(len(sequence_i)/len(tokenized_Hraf[\"train\"])*100,1)}%')\n",
    "print(sequence_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Stratification using multilabels is a difficult process as the number of unique bins of stratification increases exponentially by the number of labels (see more info and potential ways to conduct multilabel sttratification sampling <a href=\"https://dl.acm.org/doi/10.5555/2034161.2034172\"> HERE  </a>). We will currently disregard focusing on stratification of all the labels/classifications and just use a single label for stratification. Currently, this is still giving decent splits that do not deviate far from the true proportion or between n_splits. Still, one should check the proportional deviation of each label to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "EVENT:  0.6591883866710656\n",
      "CAUSE:  0.4947212141207522\n",
      "ACTION: 0.49719564500164964\n",
      "\n",
      "Fold: 2\n",
      "EVENT:  0.6517650940283735\n",
      "CAUSE:  0.4907621247113164\n",
      "ACTION: 0.49719564500164964\n",
      "\n",
      "Fold: 3\n",
      "EVENT:  0.6547344110854504\n",
      "CAUSE:  0.4915869350049489\n",
      "ACTION: 0.49719564500164964\n",
      "\n",
      "Fold: 4\n",
      "EVENT:  0.6523173346528122\n",
      "CAUSE:  0.49348507339600856\n",
      "ACTION: 0.4972785749628897\n",
      "\n",
      "Fold: 5\n",
      "EVENT:  0.6552861619660234\n",
      "CAUSE:  0.4924954642916048\n",
      "ACTION: 0.4972785749628897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Splitting\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# folds = StratifiedKFold(n_splits=5)\n",
    "folds = StratifiedKFold(n_splits=5, shuffle= True, random_state=10)\n",
    "splits = folds.split(np.zeros(Hraf['train'].num_rows), Hraf['train']['ACTION'])\n",
    "\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(splits, start=1):\n",
    "    train_list += [train_idxs]\n",
    "    val_list += [val_idxs]\n",
    "    print(\"Fold:\",fold)\n",
    "    print(f\"EVENT:  {np.mean(Hraf['train'][train_idxs]['EVENT'])}\\nCAUSE:  {np.mean(Hraf['train'][train_idxs]['CAUSE'])}\\nACTION: {np.mean(Hraf['train'][train_idxs]['ACTION'])}\\n\")\n",
    "    \n",
    "# print(train_list,\"\\n\", val_list)\n",
    "# print(train_idxs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a batch of examples using <a href=\"https://huggingface.co/docs/transformers/v4.29.0/en/main_classes/data_collator#transformers.DataCollatorWithPadding\"> DataCollatorWithPadding</a>. It’s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set tokenized passages to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_Hraf.set_format(\"torch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain F1 score for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction, TrainerCallback\n",
    "import torch\n",
    "\n",
    "# Get Metric performance\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "# Compute evaluation\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result\n",
    "\n",
    "\n",
    "# # Retrieving best model\n",
    "# class BestCheckpointCallback(TrainerCallback):\n",
    "#     def __init__(self):\n",
    "#         self.best_checkpoint = None\n",
    "\n",
    "#     def on_save(self, args, state, control, **kwargs):\n",
    "#         # Update the best_checkpoint variable when a new best checkpoint is saved\n",
    "#         self.best_checkpoint = control.value\n",
    "# # Initialize the callback\n",
    "# best_checkpoint_callback = BestCheckpointCallback()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train\n",
    "Before you start training your model, create a map of the expected ids to their labels with id2label and label2id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    problem_type='multi_label_classification',\n",
    "    num_labels = len(labels), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "# Get initial state (this is for later kfolds loops which appear to have data leakage)\n",
    "initial_model_state = {name: param.data.clone() for name, param in model.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6838, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.0804,  0.0529, -0.0312]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass (NOT IMPLEMENTED YET, JUST A TEST)\n",
    "outputs = model(input_ids=tokenized_Hraf['train']['input_ids'][0].unsqueeze(0), labels=tokenized_Hraf['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Optional Paramters\n",
    "\n",
    "# ### OPTIONAL If it crashes on a fold, you may skip the fold by specifying the start.\n",
    "# ### Set to 1 after a successful run\n",
    "# # start_fold = 1\n",
    "# # # # Set it to true if you want the model to start from a checkpoint, \n",
    "# # # # You can also specify a specific checkpoint. Otherwise choose False, normally, this may be good to set False unless a crash occurs\n",
    "# # resume_bool = '/checkpoint-434' \n",
    "# # #set True if you want to start at the beginnning\n",
    "# # overwrite_training = False \n",
    "\n",
    "\n",
    "# # Create Eval_dataset (be aware this may raise a prompt you must fill in)\n",
    "# # only create a new eval_df if one does not exist (this step is useful in case of a crash)\n",
    "# if 'eval_df' not in locals(): \n",
    "#     eval_df = pd.DataFrame()\n",
    "# else:\n",
    "#     eval_inputAppend = input(\"eval_df found, would you like to append to there? (y/n)\")\n",
    "#     if eval_inputAppend.lower() =='y':\n",
    "#         print(\"Appending to old eval dataframe, this is useful if you must restart training\")\n",
    "#         # fix issues with starting fold\n",
    "#         if max(eval_df['fold']) >= start_fold: \n",
    "#             Start_fold_input = input(f\"Your starting fold ({start_fold}) is not greater than the largest fold in the eval_df ({max(eval_df['fold'])}), this may mean redoing folds. Is this what you want (y/n)\")\n",
    "#             if Start_fold_input.lower() != 'y':\n",
    "#                 raise Exception('Quitting run, please redo your start_fold parameter')\n",
    "#     else:\n",
    "#         eval_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Versions (run only 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2170\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 1--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9716b3881d34af0ab3abe82de3e8101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daeb29fc17324a6a9fff47d367aae40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.423545241355896, 'eval_f1': 0.8451061133987963, 'eval_roc_auc': 0.799144889130704, 'eval_accuracy': 0.5875576036866359, 'eval_runtime': 197.0423, 'eval_samples_per_second': 4.405, 'eval_steps_per_second': 0.553, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.501, 'learning_rate': 1.5391705069124425e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dbe883db094208aa1bf8abc886dcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43711310625076294, 'eval_f1': 0.8546744831842024, 'eval_roc_auc': 0.800649621934365, 'eval_accuracy': 0.6059907834101382, 'eval_runtime': 198.5329, 'eval_samples_per_second': 4.372, 'eval_steps_per_second': 0.549, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3398, 'learning_rate': 1.0783410138248848e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7074caf52a341c7be95eb6088a80cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.445345401763916, 'eval_f1': 0.8537477148080439, 'eval_roc_auc': 0.7943531834996758, 'eval_accuracy': 0.5933179723502304, 'eval_runtime': 197.4677, 'eval_samples_per_second': 4.396, 'eval_steps_per_second': 0.552, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2458, 'learning_rate': 6.175115207373272e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c0b419ee514b7685724d929d4d3542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44958022236824036, 'eval_f1': 0.8570538772967923, 'eval_roc_auc': 0.8073972373154303, 'eval_accuracy': 0.6071428571428571, 'eval_runtime': 197.553, 'eval_samples_per_second': 4.394, 'eval_steps_per_second': 0.552, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1775, 'learning_rate': 1.5668202764976959e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e81aaa28784fa1ba6cbe6f7076e482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45325857400894165, 'eval_f1': 0.8584240871236386, 'eval_roc_auc': 0.8200623753646457, 'eval_accuracy': 0.618663594470046, 'eval_runtime': 196.8385, 'eval_samples_per_second': 4.41, 'eval_steps_per_second': 0.554, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170 (score: 0.8584240871236386).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14017.5835, 'train_samples_per_second': 1.238, 'train_steps_per_second': 0.155, 'train_loss': 0.3030908848283478, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f12a5c6bee84b4b9b79d3614da632fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3472\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2170\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 2--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7691d885586542cd91ff3ace347422e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6b8c0cb12c4f30914a8d4a9ffbc05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1457630842924118, 'eval_f1': 0.957901554404145, 'eval_roc_auc': 0.947026282762066, 'eval_accuracy': 0.868663594470046, 'eval_runtime': 192.4012, 'eval_samples_per_second': 4.511, 'eval_steps_per_second': 0.567, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2371, 'learning_rate': 1.5391705069124425e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce83161b58bc404797ec95f48a81b12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14711026847362518, 'eval_f1': 0.9567446331304069, 'eval_roc_auc': 0.9427110114659616, 'eval_accuracy': 0.8675115207373272, 'eval_runtime': 190.7769, 'eval_samples_per_second': 4.55, 'eval_steps_per_second': 0.571, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1446, 'learning_rate': 1.0783410138248848e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2c312011ec4b33af750701861f777b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15874063968658447, 'eval_f1': 0.9527760051052967, 'eval_roc_auc': 0.9366362451108214, 'eval_accuracy': 0.8536866359447005, 'eval_runtime': 191.2927, 'eval_samples_per_second': 4.538, 'eval_steps_per_second': 0.57, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0791, 'learning_rate': 6.175115207373272e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1e930e3d3c4f94b299efe7379d3ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15558165311813354, 'eval_f1': 0.9584273283918788, 'eval_roc_auc': 0.9463628166542787, 'eval_accuracy': 0.868663594470046, 'eval_runtime': 191.4648, 'eval_samples_per_second': 4.533, 'eval_steps_per_second': 0.569, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0482, 'learning_rate': 1.5668202764976959e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9745b83ed5a485bb4064f040369e192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1686871498823166, 'eval_f1': 0.9556052379431491, 'eval_roc_auc': 0.9404178191521768, 'eval_accuracy': 0.8582949308755761, 'eval_runtime': 191.7016, 'eval_samples_per_second': 4.528, 'eval_steps_per_second': 0.569, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736 (score: 0.9584273283918788).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13973.7607, 'train_samples_per_second': 1.242, 'train_steps_per_second': 0.155, 'train_loss': 0.12036735297348093, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175039b8e08a42d7877627cf0ea31037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3472\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2170\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 3--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5dd78138464ecdaed90086d9da9a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b51bf75fe5040998110c7cc89244f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04312153905630112, 'eval_f1': 0.989540412044374, 'eval_roc_auc': 0.9852195945945947, 'eval_accuracy': 0.9642857142857143, 'eval_runtime': 196.3134, 'eval_samples_per_second': 4.422, 'eval_steps_per_second': 0.555, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1097, 'learning_rate': 1.5391705069124425e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c22d7c8fce454b978e0e93bb01653d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.035966116935014725, 'eval_f1': 0.9911280101394169, 'eval_roc_auc': 0.9871414782129069, 'eval_accuracy': 0.9711981566820277, 'eval_runtime': 196.4649, 'eval_samples_per_second': 4.418, 'eval_steps_per_second': 0.555, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0631, 'learning_rate': 1.0783410138248848e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a6044c92624911a9ae9a6be75ea2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02918880246579647, 'eval_f1': 0.9923906150919467, 'eval_roc_auc': 0.9889082322118036, 'eval_accuracy': 0.9758064516129032, 'eval_runtime': 196.1773, 'eval_samples_per_second': 4.425, 'eval_steps_per_second': 0.556, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0286, 'learning_rate': 6.175115207373272e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6fd1ad97ab4962a696995df68143ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.029055986553430557, 'eval_f1': 0.9911280101394169, 'eval_roc_auc': 0.9871414782129069, 'eval_accuracy': 0.9711981566820277, 'eval_runtime': 196.0693, 'eval_samples_per_second': 4.427, 'eval_steps_per_second': 0.556, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0113, 'learning_rate': 1.5668202764976959e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6a5dc1b5a743e3a1ed62555841d9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02619864046573639, 'eval_f1': 0.9926960939980947, 'eval_roc_auc': 0.9897183535576393, 'eval_accuracy': 0.978110599078341, 'eval_runtime': 195.6949, 'eval_samples_per_second': 4.435, 'eval_steps_per_second': 0.557, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170 (score: 0.9926960939980947).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13842.7568, 'train_samples_per_second': 1.254, 'train_steps_per_second': 0.157, 'train_loss': 0.04961150511069232, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b61618d65342d38b8c2ce0df1e690b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3472\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2170\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 4--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ac2f0a94014070ba0889c2185ce079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fab1a8e0874ec691890a381beb1421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.009037306532263756, 'eval_f1': 0.996968676321994, 'eval_roc_auc': 0.9962058065773236, 'eval_accuracy': 0.9896313364055299, 'eval_runtime': 199.131, 'eval_samples_per_second': 4.359, 'eval_steps_per_second': 0.547, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0354, 'learning_rate': 1.5391705069124425e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bb7675c32b4ac3aca3452c4b804a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00467693293467164, 'eval_f1': 0.9986522911051213, 'eval_roc_auc': 0.9982174688057042, 'eval_accuracy': 0.9953917050691244, 'eval_runtime': 199.0299, 'eval_samples_per_second': 4.361, 'eval_steps_per_second': 0.548, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0265, 'learning_rate': 1.0783410138248848e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb1c3f0d48a4eb7ad2f543f32738a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004247164353728294, 'eval_f1': 0.9986504723346828, 'eval_roc_auc': 0.9984339705701936, 'eval_accuracy': 0.9953917050691244, 'eval_runtime': 199.0542, 'eval_samples_per_second': 4.361, 'eval_steps_per_second': 0.548, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0101, 'learning_rate': 6.175115207373272e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c7cff40ab04d19ac7372d0f6bddc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0020585672464221716, 'eval_f1': 0.9989875126560918, 'eval_roc_auc': 0.9988796033687675, 'eval_accuracy': 0.9965437788018433, 'eval_runtime': 198.7473, 'eval_samples_per_second': 4.367, 'eval_steps_per_second': 0.548, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.003, 'learning_rate': 1.5668202764976959e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb0cfa9eb1d49939aa7c656a5be3f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0025650858879089355, 'eval_f1': 0.9993252361673415, 'eval_roc_auc': 0.9992169852850968, 'eval_accuracy': 0.9976958525345622, 'eval_runtime': 198.499, 'eval_samples_per_second': 4.373, 'eval_steps_per_second': 0.549, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170 (score: 0.9993252361673415).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13692.8755, 'train_samples_per_second': 1.268, 'train_steps_per_second': 0.158, 'train_loss': 0.017497836540920943, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c60edb1981e42959c378ed2c62a02f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3472\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2170\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 5--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fb9f2514844e379cc700f8dc0e4595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa30037b94245fc8e0330317a24083f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0006783527787774801, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 199.8549, 'eval_samples_per_second': 4.343, 'eval_steps_per_second': 0.545, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0209, 'learning_rate': 1.5391705069124425e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86ca8cfb31c43c6b5027698cc3ba46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.001404578099027276, 'eval_f1': 0.9996743731683491, 'eval_roc_auc': 0.9996744791666667, 'eval_accuracy': 0.9988479262672811, 'eval_runtime': 200.5795, 'eval_samples_per_second': 4.327, 'eval_steps_per_second': 0.543, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-868/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0173, 'learning_rate': 1.0783410138248848e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803dbfb0c4154901881b7960fc6083e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003970277030020952, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 201.8827, 'eval_samples_per_second': 4.3, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1302/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0061, 'learning_rate': 6.175115207373272e-06, 'epoch': 3.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359dcfb8c5bd41e5ba0f88998ee52e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003000223950948566, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 202.0393, 'eval_samples_per_second': 4.296, 'eval_steps_per_second': 0.539, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1736/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0026, 'learning_rate': 1.5668202764976959e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f704bb0a94ad48189a841bcc13f098a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017800420755520463, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 203.0652, 'eval_samples_per_second': 4.274, 'eval_steps_per_second': 0.537, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-2170/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 868\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13688.5703, 'train_samples_per_second': 1.268, 'train_steps_per_second': 0.159, 'train_loss': 0.01084896839022087, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47edc8104b9b4d6a927729bfcf7c46fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "assert (start_fold >0) and (start_fold <= len(train_list)), f\"Incorrect Starting fold, must be greater than or equal to 1 and less than or equal to {len(train_list)}\"\n",
    "for fold, (train_idxs, val_idxs) in enumerate(zip(train_list, val_list), start=1): # K-fold loop\n",
    "    \n",
    "    #Skip folds if desired\n",
    "    if start_fold >fold:\n",
    "        print('\\033[93m'+ f\"Skipping Fold {fold}\"+ '\\033[0m')\n",
    "        continue\n",
    "\n",
    "    print(f\"------Fold {fold}--------\\n\")\n",
    "    train_ds = tokenized_Hraf[\"train\"].select(train_idxs)\n",
    "    val_ds = tokenized_Hraf[\"train\"].select(val_idxs)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        \n",
    "    )\n",
    "    try:\n",
    "        trainer.train() \n",
    "    except:\n",
    "        print('\\033[93m'+ f\"A crash occurred, restarting fold from checkpoint\"+ '\\033[0m')\n",
    "        trainer.train(resume_from_checkpoint=True) #This is the same thing above but often restarting can make all the difference so let's try it\n",
    "\n",
    "    # Evaluate and then concatinate results to a dataframe\n",
    "    eval_dict = trainer.evaluate()\n",
    "    eval_df_line = pd.DataFrame([eval_dict])\n",
    "    eval_df_line[\"fold\"] = fold\n",
    "    eval_df_line[\"train_count\"] = len(train_ds)\n",
    "    eval_df_line[\"val_count\"] = len(val_ds)\n",
    "    eval_df_line[\"total_count\"] = eval_df_line[\"val_count\"] + eval_df_line[\"train_count\"]\n",
    "    eval_df = pd.concat([eval_df, eval_df_line])\n",
    "\n",
    "\n",
    "\n",
    "# Save the model to disk\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Repository.__init__() got an unexpected keyword argument 'private'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_DEMO/HRAF_Training_multiLabel_ThreeLargeClasses_DEMO.ipynb Cell 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_DEMO/HRAF_Training_multiLabel_ThreeLargeClasses_DEMO.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mpush_to_hub()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/trainer.py:3431\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3428\u001b[0m \u001b[39m# If a user calls manually `push_to_hub` with `self.args.push_to_hub = False`, we try to create the repo but\u001b[39;00m\n\u001b[1;32m   3429\u001b[0m \u001b[39m# it might fail.\u001b[39;00m\n\u001b[1;32m   3430\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrepo\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 3431\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo()\n\u001b[1;32m   3433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m   3434\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_model_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/trainer.py:3284\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[0;34m(self, at_init)\u001b[0m\n\u001b[1;32m   3281\u001b[0m     repo_name \u001b[39m=\u001b[39m get_full_repo_name(repo_name, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_token)\n\u001b[1;32m   3283\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepo \u001b[39m=\u001b[39m Repository(\n\u001b[1;32m   3285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49moutput_dir,\n\u001b[1;32m   3286\u001b[0m         clone_from\u001b[39m=\u001b[39;49mrepo_name,\n\u001b[1;32m   3287\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   3288\u001b[0m         private\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_private_repo,\n\u001b[1;32m   3289\u001b[0m     )\n\u001b[1;32m   3290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m   3291\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moverwrite_output_dir \u001b[39mand\u001b[39;00m at_init:\n\u001b[1;32m   3292\u001b[0m         \u001b[39m# Try again after wiping output_dir\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Repository.__init__() got an unexpected keyword argument 'private'"
     ]
    }
   ],
   "source": [
    "# Push to hub (I have not gotten this to work so alternatively you can manually add in the best checkpoint by uploading the checkpoint into your hugging face account)\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Decay Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code attempts to investigate the best weight decay for the model by initiallizing training for each weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_save(eval_df, dataset=Hraf, overwrite_training=True):\n",
    "    # Augment Evaluation File \n",
    "    from datetime import date\n",
    "\n",
    "    today = date.today()\n",
    "    date_tm = today.strftime(\"%y/%m/%d\")\n",
    "\n",
    "    #reorganize columns\n",
    "    cols = list(eval_df.columns.values) \n",
    "    remove_list = [\"fold\", \"epoch\",\"weight_decay\", \"learning_rate\"]\n",
    "    for removal in remove_list:\n",
    "        cols.remove(removal)\n",
    "    cols = remove_list+cols\n",
    "    eval_df = eval_df[cols]\n",
    "\n",
    "\n",
    "    trainingStatus = 'Initial Training' if overwrite_training == True else 'Continue Training'\n",
    "\n",
    "    info_df  = pd.DataFrame({\"Date\":len(eval_df)*[date_tm],\"Train_status\":len(eval_df)*[trainingStatus]})\n",
    "    eval_df = eval_df.reset_index(drop=True)\n",
    "    eval_df = pd.concat([info_df, eval_df], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    # import evaluation if it exists\n",
    "    if os.path.exists(\"Evaluation.xlsx\"):\n",
    "        old_eval = pd.read_excel(\"Evaluation.xlsx\", sheet_name=\"Sheet1\", index_col=0)\n",
    "        eval_df = pd.concat([old_eval, eval_df])\n",
    "\n",
    "    eval_df.to_excel('Evaluation.xlsx')\n",
    "# Run this if your model crashes and you want to save after the fact\n",
    "# eval_save(dataset=Hraf, eval_df=eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELETE\n",
    "\n",
    "# eval_df = pd.DataFrame()\n",
    "# fold_f1s = []\n",
    "# fold_f1 = eval_dict['eval_f1']\n",
    "# fold_f1s.append(fold_f1)\n",
    "# print(f\"Fold {fold} Accuracy: {fold_f1}\")\n",
    "\n",
    "# eval_df_line = pd.DataFrame([eval_dict])\n",
    "# eval_df_line[\"fold\"] = fold\n",
    "# eval_df_line[\"weight_decay\"] = weight_decay\n",
    "# eval_df_line[\"learning_rate\"] = learning_rate\n",
    "# eval_df_line[\"train_count\"] = len(train_ds)\n",
    "# eval_df_line[\"val_count\"] = len(val_ds)\n",
    "# eval_df_line[\"total_count\"] = eval_df_line[\"val_count\"] + eval_df_line[\"train_count\"]\n",
    "# eval_df = pd.concat([eval_df, eval_df_line])\n",
    "# eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are re-running the model, you must respecify the model. For reasons that I have yet to determine, Huggingface uses a cached model (I believe) every loop and thus causes a data leak that makes folds not indpendent of each other. This is a bad thing and can make the data overfitted and a less reliable estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available()\n",
    "# device = torch.device('mps')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "# PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-06_fold_1 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-06_fold_2 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-06_fold_3 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-06_fold_4 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-06_fold_5 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mNo F1's in list, this likely means all the folds were skipped\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-05_fold_1 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-05_fold_2 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-05_fold_3 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-05_fold_4 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_1e-05_fold_5 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mNo F1's in list, this likely means all the folds were skipped\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.0001_fold_1 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.0001_fold_2 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.0001_fold_3 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.0001_fold_4 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.0001_fold_5 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mNo F1's in list, this likely means all the folds were skipped\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.001_fold_1 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.001_fold_2 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.001_fold_3 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.001_fold_4 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.001_fold_5 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mNo F1's in list, this likely means all the folds were skipped\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.01_fold_1 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.01_fold_2 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mSkipping HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.01_fold_3 as it is indicated as finished\u001b[0m\n",
      "\u001b[93mStarting from last checkpoint HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation/output_dir_0.01_fold_4\u001b[0m\n",
      "------Fold 4/5--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63336494b2374bc79376746f0640a1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1733, 'grad_norm': 3.3595187664031982, 'learning_rate': 3.6411609498680746e-06, 'epoch': 4.09}\n",
      "{'loss': 0.1311, 'grad_norm': 13.486773490905762, 'learning_rate': 3.1134564643799476e-06, 'epoch': 4.22}\n",
      "{'loss': 0.1109, 'grad_norm': 3.1867263317108154, 'learning_rate': 2.5857519788918206e-06, 'epoch': 4.35}\n",
      "{'loss': 0.1307, 'grad_norm': 2.514549493789673, 'learning_rate': 2.058047493403694e-06, 'epoch': 4.49}\n",
      "{'loss': 0.1282, 'grad_norm': 5.564957141876221, 'learning_rate': 1.5303430079155673e-06, 'epoch': 4.62}\n",
      "{'loss': 0.1379, 'grad_norm': 4.532524585723877, 'learning_rate': 1.0026385224274407e-06, 'epoch': 4.75}\n",
      "{'loss': 0.1322, 'grad_norm': 3.9431843757629395, 'learning_rate': 4.7493403693931397e-07, 'epoch': 4.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f1f18d6f524ec18ce0b5ec9ad031fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46793022751808167, 'eval_f1': 0.8606955508062949, 'eval_roc_auc': 0.8373765281173594, 'eval_accuracy': 0.6580858085808581, 'eval_runtime': 330.9321, 'eval_samples_per_second': 4.578, 'eval_steps_per_second': 0.574, 'epoch': 5.0}\n",
      "{'train_runtime': 5248.3053, 'train_samples_per_second': 5.776, 'train_steps_per_second': 0.722, 'train_loss': 0.025964097297285983, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ce00d31c324bf6af23cbedc8e2bbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1: 0.8606955508062949\n",
      "------Fold 5/5--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8007e26596c14e309f1bd3627b2b6fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6056, 'grad_norm': 1.8332290649414062, 'learning_rate': 1.9472295514511874e-05, 'epoch': 0.13}\n",
      "{'loss': 0.4921, 'grad_norm': 3.7581775188446045, 'learning_rate': 1.894459102902375e-05, 'epoch': 0.26}\n",
      "{'loss': 0.4665, 'grad_norm': 5.812331199645996, 'learning_rate': 1.8416886543535623e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4206, 'grad_norm': 6.1683549880981445, 'learning_rate': 1.7889182058047495e-05, 'epoch': 0.53}\n",
      "{'loss': 0.41, 'grad_norm': 8.479280471801758, 'learning_rate': 1.7361477572559368e-05, 'epoch': 0.66}\n",
      "{'loss': 0.4293, 'grad_norm': 2.9700231552124023, 'learning_rate': 1.683377308707124e-05, 'epoch': 0.79}\n",
      "{'loss': 0.404, 'grad_norm': 4.1815924644470215, 'learning_rate': 1.6306068601583113e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff56727316a74fc39409340462788c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38801276683807373, 'eval_f1': 0.8456402994133118, 'eval_roc_auc': 0.8312946381815993, 'eval_accuracy': 0.633003300330033, 'eval_runtime': 330.8984, 'eval_samples_per_second': 4.578, 'eval_steps_per_second': 0.574, 'epoch': 1.0}\n",
      "{'loss': 0.3571, 'grad_norm': 2.0961878299713135, 'learning_rate': 1.577836411609499e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3467, 'grad_norm': 2.2172343730926514, 'learning_rate': 1.5250659630606862e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3376, 'grad_norm': 2.6702523231506348, 'learning_rate': 1.4722955145118736e-05, 'epoch': 1.32}\n",
      "{'loss': 0.3185, 'grad_norm': 4.551942348480225, 'learning_rate': 1.4195250659630609e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3049, 'grad_norm': 9.708532333374023, 'learning_rate': 1.3667546174142481e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3304, 'grad_norm': 8.946589469909668, 'learning_rate': 1.3139841688654355e-05, 'epoch': 1.72}\n",
      "{'loss': 0.3155, 'grad_norm': 5.656391143798828, 'learning_rate': 1.2612137203166228e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3284, 'grad_norm': 4.433426856994629, 'learning_rate': 1.20844327176781e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1319659e9a3e4275bf2f3da6b39cbfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3947567045688629, 'eval_f1': 0.8493256262042389, 'eval_roc_auc': 0.8218759720943467, 'eval_accuracy': 0.6323432343234323, 'eval_runtime': 330.0171, 'eval_samples_per_second': 4.591, 'eval_steps_per_second': 0.576, 'epoch': 2.0}\n",
      "{'loss': 0.2259, 'grad_norm': 11.120250701904297, 'learning_rate': 1.1556728232189975e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2618, 'grad_norm': 2.992271900177002, 'learning_rate': 1.1029023746701847e-05, 'epoch': 2.24}\n",
      "{'loss': 0.2263, 'grad_norm': 5.019251823425293, 'learning_rate': 1.050131926121372e-05, 'epoch': 2.37}\n",
      "{'loss': 0.2316, 'grad_norm': 4.047245025634766, 'learning_rate': 9.973614775725594e-06, 'epoch': 2.51}\n",
      "{'loss': 0.2574, 'grad_norm': 13.14600944519043, 'learning_rate': 9.445910290237469e-06, 'epoch': 2.64}\n",
      "{'loss': 0.2447, 'grad_norm': 8.431661605834961, 'learning_rate': 8.918205804749341e-06, 'epoch': 2.77}\n",
      "{'loss': 0.2491, 'grad_norm': 4.99027156829834, 'learning_rate': 8.390501319261214e-06, 'epoch': 2.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdbaeaaa7f44388808b9af36b31f444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4343133568763733, 'eval_f1': 0.8503453568687643, 'eval_roc_auc': 0.8218568233011895, 'eval_accuracy': 0.6336633663366337, 'eval_runtime': 331.6739, 'eval_samples_per_second': 4.568, 'eval_steps_per_second': 0.573, 'epoch': 3.0}\n",
      "{'loss': 0.212, 'grad_norm': 4.191608428955078, 'learning_rate': 7.862796833773088e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1583, 'grad_norm': 12.622949600219727, 'learning_rate': 7.3350923482849614e-06, 'epoch': 3.17}\n",
      "{'loss': 0.1924, 'grad_norm': 9.256453514099121, 'learning_rate': 6.807387862796835e-06, 'epoch': 3.3}\n",
      "{'loss': 0.1573, 'grad_norm': 5.695972442626953, 'learning_rate': 6.2796833773087074e-06, 'epoch': 3.43}\n",
      "{'loss': 0.1692, 'grad_norm': 6.834404468536377, 'learning_rate': 5.751978891820581e-06, 'epoch': 3.56}\n",
      "{'loss': 0.1607, 'grad_norm': 3.8109517097473145, 'learning_rate': 5.224274406332454e-06, 'epoch': 3.69}\n",
      "{'loss': 0.1728, 'grad_norm': 2.854853630065918, 'learning_rate': 4.696569920844328e-06, 'epoch': 3.83}\n",
      "{'loss': 0.1951, 'grad_norm': 8.285879135131836, 'learning_rate': 4.168865435356201e-06, 'epoch': 3.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f43db2c0b194267bcd9a1d264c19a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5068909525871277, 'eval_f1': 0.8467620481927711, 'eval_roc_auc': 0.8122028029143681, 'eval_accuracy': 0.6257425742574257, 'eval_runtime': 329.3474, 'eval_samples_per_second': 4.6, 'eval_steps_per_second': 0.577, 'epoch': 4.0}\n",
      "{'loss': 0.1413, 'grad_norm': 4.882196426391602, 'learning_rate': 3.6411609498680746e-06, 'epoch': 4.09}\n",
      "{'loss': 0.1497, 'grad_norm': 15.466547012329102, 'learning_rate': 3.1134564643799476e-06, 'epoch': 4.22}\n",
      "{'loss': 0.1288, 'grad_norm': 4.238325119018555, 'learning_rate': 2.5857519788918206e-06, 'epoch': 4.35}\n",
      "{'loss': 0.1371, 'grad_norm': 0.7318606972694397, 'learning_rate': 2.058047493403694e-06, 'epoch': 4.49}\n",
      "{'loss': 0.132, 'grad_norm': 1.088075876235962, 'learning_rate': 1.5303430079155673e-06, 'epoch': 4.62}\n",
      "{'loss': 0.1154, 'grad_norm': 1.0877991914749146, 'learning_rate': 1.0026385224274407e-06, 'epoch': 4.75}\n",
      "{'loss': 0.1264, 'grad_norm': 3.2048089504241943, 'learning_rate': 4.7493403693931397e-07, 'epoch': 4.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbf6fce9b29421a9241c81d9b44b4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5063793063163757, 'eval_f1': 0.8489180834621329, 'eval_roc_auc': 0.8221707267318716, 'eval_accuracy': 0.6356435643564357, 'eval_runtime': 328.7802, 'eval_samples_per_second': 4.608, 'eval_steps_per_second': 0.578, 'epoch': 5.0}\n",
      "{'train_runtime': 23628.9965, 'train_samples_per_second': 1.283, 'train_steps_per_second': 0.16, 'train_loss': 0.2641790729713943, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb1be7173c046d9b0cf423365512ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1: 0.8489180834621329\n",
      "\u001b[93mWarning less F1's than expected, likely some folds were skipped and thus the mean f1 may be off\u001b[0m\n",
      "Average Accuracy for Weight Decay 0.01: 0.8548068171342139\n",
      "Best Weight Decay: 1e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO_WeightInvestigation\"\n",
    "\n",
    "\n",
    "# Define a range of weight decay values to test\n",
    "weight_decay_values = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "# weight_decay_values = [1e-2]\n",
    "learning_rate = 2e-5\n",
    "# Track the average validation accuracy for each weight decay value\n",
    "avg_validation_f1s = []\n",
    "\n",
    "\n",
    "\n",
    "for weight_decay in weight_decay_values:\n",
    "    fold_f1s = []\n",
    "\n",
    "\n",
    "    eval_df = pd.DataFrame()\n",
    "    # # Train the model\n",
    "    # assert (start_fold >0) and (start_fold <= len(train_list)), f\"Incorrect Starting fold, must be greater than or equal to 1 and less than or equal to {len(train_list)}\"\n",
    "    for fold, (train_idxs, val_idxs) in enumerate(zip(train_list, val_list), start=1): # K-fold loop\n",
    "        \n",
    "\n",
    "        output_dir = f\"{model_name}/output_dir_{weight_decay}_fold_{fold}\"\n",
    "\n",
    "        resume_bool = False\n",
    "        \n",
    "\n",
    "        #Skip folds already completed\n",
    "        if os.path.exists(f\"{output_dir}\"):\n",
    "            if os.path.exists(f\"{output_dir}/finished.txt\"):\n",
    "                print('\\033[93m'+ f\"Skipping {output_dir} as it is indicated as finished\" + '\\033[0m')\n",
    "                continue\n",
    "            else:\n",
    "                print('\\033[93m'+ f\"Starting from last checkpoint {output_dir}\"+ '\\033[0m')\n",
    "                resume_bool = True # resume from the last checkpoint if there is an output folder but it is not finished.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"------Fold {fold}/{len(train_list)}--------\\n\")\n",
    "\n",
    "        #reinitialize the model (since it appears to be dataleaking over loops)\n",
    "        model.load_state_dict(initial_model_state)\n",
    "        for name, param in model.named_parameters():\n",
    "                try:\n",
    "                    assert (np.array(initial_model_state[name]) == np.array(param.data)).all(), \"Parameters differ from original model\"\n",
    "                except:\n",
    "                    print(name, \"Differs from initial model\")\n",
    "        model.load_state_dict(initial_model_state)\n",
    "\n",
    "        train_ds = tokenized_Hraf[\"train\"].select(train_idxs)\n",
    "        val_ds = tokenized_Hraf[\"train\"].select(val_idxs)\n",
    "\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=8,  # should be multiples of 8\n",
    "            per_device_eval_batch_size=8, # should be multiples of 8\n",
    "            num_train_epochs=5,\n",
    "            weight_decay=weight_decay,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            metric_for_best_model='f1',\n",
    "            push_to_hub=False,\n",
    "            logging_dir=f\"{model_name}/logs_{weight_decay}_fold_{fold}\",\n",
    "            logging_steps=100,\n",
    "            use_cpu=True, # set True or False depending on if you want ot use the GPU, which is faster but has been unreliable on Macs\n",
    "        )\n",
    "\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_ds,\n",
    "            eval_dataset=val_ds,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            # callbacks=[best_checkpoint_callback], \n",
    "            compute_metrics=compute_metrics,\n",
    "            \n",
    "        )\n",
    "        try:\n",
    "            trainer.train(resume_from_checkpoint = resume_bool) \n",
    "        except:\n",
    "            print('\\033[91m'+ f\"A crash occurred, restarting fold from checkpoint\"+ '\\033[0m')\n",
    "            trainer.train(resume_from_checkpoint=True) #This is the same thing above but often restarting can make all the difference so let's try it\n",
    "\n",
    "        # Evaluate and then concatinate results to a dataframe\n",
    "\n",
    "        # Evaluate on validation set for this fold\n",
    "        eval_dict = trainer.evaluate(val_ds)\n",
    "        fold_f1 = eval_dict['eval_f1']\n",
    "        fold_f1s.append(fold_f1)\n",
    "        print(f\"Fold {fold} F1: {fold_f1}\")\n",
    "\n",
    "        eval_df_line = pd.DataFrame([eval_dict])\n",
    "        eval_df_line[\"fold\"] = fold\n",
    "        eval_df_line[\"weight_decay\"] = weight_decay\n",
    "        eval_df_line[\"learning_rate\"] = learning_rate\n",
    "        eval_df_line[\"fold_f1\"] = fold_f1\n",
    "        eval_df_line[\"train_count\"] = len(train_ds)\n",
    "        eval_df_line[\"val_count\"] = len(val_ds)\n",
    "        eval_df_line[\"total_count\"] = eval_df_line[\"val_count\"] + eval_df_line[\"train_count\"]\n",
    "        eval_df = pd.concat([eval_df, eval_df_line])\n",
    "\n",
    "        # # Get best model and then finish\n",
    "        # best_checkpoint = best_checkpoint_callback.best_checkpoint\n",
    "        # print(\"Best Checkpoint:\", best_checkpoint)\n",
    "        \n",
    "        # Save Best model\n",
    "        f = open(f\"{output_dir}/finished.txt\", \"w\")\n",
    "        f.write(f\"Best Model: TBD code incomplete\")\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "    # Calculate average accuracy for this weight decay value\n",
    "    if len(fold_f1s) == 0:\n",
    "        print('\\033[93m'+ f\"No F1's in list, this likely means all the folds were skipped\" + '\\033[0m')\n",
    "        continue\n",
    "    elif len(fold_f1s) < len(train_list):\n",
    "        print('\\033[93m'+ f\"Warning less F1's than expected, likely some folds were skipped and thus the mean f1 may be off\" + '\\033[0m')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    avg_f1 = np.mean(fold_f1s)\n",
    "    avg_validation_f1s.append(avg_f1)\n",
    "    print(f\"Average Accuracy for Weight Decay {weight_decay}: {avg_f1}\")\n",
    "    #Save evaluation File\n",
    "    eval_save(dataset=Hraf, eval_df=eval_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Choose the weight decay with the highest average validation accuracy\n",
    "best_weight_decay = weight_decay_values[np.argmax(avg_validation_f1s)]\n",
    "print(f\"Best Weight Decay: {best_weight_decay}\")\n",
    "\n",
    "\n",
    "# Save the model to disk\n",
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation Dataset columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453259</td>\n",
       "      <td>0.858424</td>\n",
       "      <td>0.820062</td>\n",
       "      <td>0.618664</td>\n",
       "      <td>198.1796</td>\n",
       "      <td>4.380</td>\n",
       "      <td>0.550</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155582</td>\n",
       "      <td>0.958427</td>\n",
       "      <td>0.946363</td>\n",
       "      <td>0.868664</td>\n",
       "      <td>193.1072</td>\n",
       "      <td>4.495</td>\n",
       "      <td>0.564</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026199</td>\n",
       "      <td>0.992696</td>\n",
       "      <td>0.989718</td>\n",
       "      <td>0.978111</td>\n",
       "      <td>197.2923</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0.552</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>201.1940</td>\n",
       "      <td>4.314</td>\n",
       "      <td>0.542</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>204.5292</td>\n",
       "      <td>4.244</td>\n",
       "      <td>0.533</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss   eval_f1  eval_roc_auc  eval_accuracy  eval_runtime   \n",
       "0   0.453259  0.858424      0.820062       0.618664      198.1796  \\\n",
       "0   0.155582  0.958427      0.946363       0.868664      193.1072   \n",
       "0   0.026199  0.992696      0.989718       0.978111      197.2923   \n",
       "0   0.002565  0.999325      0.999217       0.997696      201.1940   \n",
       "0   0.000678  1.000000      1.000000       1.000000      204.5292   \n",
       "\n",
       "   eval_samples_per_second  eval_steps_per_second  epoch  Fold  \n",
       "0                    4.380                  0.550    5.0     1  \n",
       "0                    4.495                  0.564    5.0     2  \n",
       "0                    4.400                  0.552    5.0     3  \n",
       "0                    4.314                  0.542    5.0     4  \n",
       "0                    4.244                  0.533    5.0     5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augment Evaluation File \n",
    "\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "date_tm = today.strftime(\"%y/%m/%d\")\n",
    "\n",
    "#reorganize columns\n",
    "cols = list(eval_df.columns.values) \n",
    "remove_list = [\"fold\", \"epoch\"]\n",
    "for removal in remove_list:\n",
    "    cols.remove(removal)\n",
    "cols = [\"fold\",\"epoch\"]+cols\n",
    "eval_df = eval_df[cols]\n",
    "\n",
    "numrows = sum(Hraf.num_rows.values())\n",
    "\n",
    "trainingStatus = 'Initial Training' if overwrite_training == True else 'Continue Training'\n",
    "\n",
    "info_df  = pd.DataFrame({\"Date\":len(eval_df)*[date_tm],\"Train_status\":len(eval_df)*[trainingStatus]})\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "eval_df = pd.concat([info_df, eval_df], axis=1)\n",
    "eval_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evaluation if it exists\n",
    "if os.path.exists(\"Evaluation.xlsx\"):\n",
    "    old_eval = pd.read_excel(\"Evaluation.xlsx\", index_col=0)\n",
    "    eval_df = pd.concat([old_eval, eval_df])\n",
    "\n",
    "eval_df.to_excel('Evaluation.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Partitioned Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7578 Rows for 'train' succesfully saved to /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/Datasets/train_dataset.json\n",
      "1895 Rows for 'test' succesfully saved to /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/Datasets/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "def make_dir(path):\n",
    "    import os\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "        os.makedirs(path)\n",
    "\n",
    "# make folder if it does not exist yet\n",
    "path = os.getcwd() + '/Datasets'\n",
    "make_dir(path)\n",
    "# save to Json\n",
    "for key in Hraf.keys():\n",
    "    Hraf_dict = Hraf[key].to_dict()\n",
    "    file_path = f\"{path}/{key}_dataset.json\"\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(Hraf_dict, outfile)\n",
    "        print(len(Hraf_dict['ID']), f\"Rows for \\'{key}\\' succesfully saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is meant for if you want to continue training from where you left off. It will for the most part have extremely similar code to the initial run code and even ask you to run some cells above which have needed functions. If you do not have an active dataset or model yet, this is not for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage Number Duplicates before filtering: 654\n",
      "Passage Number Duplicates after filtering: 0\n",
      "Passage Duplicates after filtering: 0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>passage</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>ACTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1392</td>\n",
       "      <td>The communal huts are used for another purpose...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>Although the Onge observe few hygienic precaut...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1395</td>\n",
       "      <td>Foods considered healthy by the Onge include h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                            passage  EVENT  CAUSE   \n",
       "0  1392  The communal huts are used for another purpose...      1      0  \\\n",
       "1  1393  Although the Onge observe few hygienic precaut...      1      0   \n",
       "2  1395  Foods considered healthy by the Onge include h...      1      1   \n",
       "\n",
       "   ACTION  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = \"../../../eHRAF_Scraper-Analysis-and-Prep/Data/\"\n",
    "dataFolder = r\"(subjects-(contracts_OR_disabilities_OR_disasters_OR_friendships_OR_gift_giving_OR_infant_feeding_OR_lineages_OR_local_officials_OR_luck_and_chance_OR_magicians_and_diviners_OR_mortuary_specialists_OR_nuclear_family_OR_priesthood_OR_prophet/\"\n",
    "# dataFolder = r'subjects-(sickness)_FILTERS-culture_level_samples(PSF)'\n",
    "\n",
    "#load df (only load one of these commented out lines)\n",
    "# df = pd.read_excel(f\"{path}{dataFolder}/_Altogether_Dataset_RACoded.xlsx\", header=[0,1], index_col=0) # Fall 2023 sickness + non-sickness\n",
    "df = pd.read_excel(f\"{path}{dataFolder}/_Altogether_Dataset_RACoded_Combined.xlsx\", header=[0,1], index_col=0) # Spring 2023 - Spring 2024  sickness + nonsickness dataset\n",
    "# df.head(3)\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "# Ideally, we want no duplicates. If there is a duplicate, prefer run 3 over run 1.\n",
    "#Take only the run number 1 and 3\n",
    "df = df.loc[(df[(\"CODER\",\"Run_Number\")]==1) | (df[(\"CODER\",\"Run_Number\")]==3)]\n",
    "dup1 = df[(\"CULTURE\",\"Passage Number\")].duplicated(keep=False) #passage number duplicates\n",
    "print(\"Passage Number Duplicates before filtering:\", sum(dup1))\n",
    "dup2 = df[(\"CODER\",\"Run_Number\")] != 3 # select all that are not run 3 (as we want to use run 3)\n",
    "df = df[~(dup1 & dup2)]\n",
    "print(\"Passage Number Duplicates after filtering:\", sum(df[(\"CULTURE\",\"Passage Number\")].duplicated(keep=False)))\n",
    "print(\"Passage Duplicates after filtering:\", sum(df[(\"CULTURE\",\"Passage\")].duplicated(keep=False)),\"\\n\")\n",
    "\n",
    "# subdivide into just passage and outcome\n",
    "df_small = pd.DataFrame()\n",
    "df_small[[\"ID\",\"passage\",\"EVENT\",\"CAUSE\",\"ACTION\"]] = df[[('CULTURE', \"Passage Number\"), ('CULTURE', \"Passage\"), ('EVENT', \"No_Info\"), ('CAUSE', \"No_Info\"), ('ACTION', \"No_Info\")]]\n",
    "# Flip the lable of \"no_info\"\n",
    "df_small[[\"EVENT\",\"CAUSE\",\"ACTION\"]]  = df_small[[\"EVENT\",\"CAUSE\",\"ACTION\"]].replace({0:1, 1:0})\n",
    "\n",
    "# Remove certain passages which should not be in training or inference (these are duplicates that had to be manually found by a human)\n",
    "values_to_remove = [3252, 33681, 6758, 10104]\n",
    "df_small = df_small[~df_small['ID'].isin(values_to_remove)]\n",
    "df_small.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and compare old dataset from JSON datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>passage</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>ACTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66159</td>\n",
       "      <td>Ancestors of the other side,/ who are also pri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8756</td>\n",
       "      <td>“So we call all these things. But each obia ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25937</td>\n",
       "      <td>In certain cases, scrutiny of recent events in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                            passage  EVENT  CAUSE   \n",
       "0  66159  Ancestors of the other side,/ who are also pri...      0      0  \\\n",
       "1   8756  “So we call all these things. But each obia ha...      0      0   \n",
       "2  25937  In certain cases, scrutiny of recent events in...      1      1   \n",
       "\n",
       "   ACTION  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = \"\"\n",
    "\n",
    "Hraf_prev = DatasetDict()\n",
    "\n",
    "dataset_names = ['train', 'test']\n",
    "\n",
    "df_prev = pd.DataFrame([])\n",
    "for name in dataset_names:\n",
    "    f = open(loc+f\"Datasets/{name}_dataset.json\")\n",
    "    data = json.load(f)\n",
    "    df_prev = pd.concat([df_prev, pd.DataFrame(data)])\n",
    "    Hraf_prev[name] = Dataset.from_dict(data) # load to hugging face dataset dict\n",
    "    # Closing file\n",
    "    f.close()\n",
    "# f = open(loc+\"Datasets/train_dataset.json\")\n",
    "# # f = open(\"../HRAF_MultiLabel_ThreeLargeClasses/Datasets/test_dataset.json\") #load old threemain class (comment this out unless you specifically are using it)\n",
    "# data = json.load(f)\n",
    "# Hraf_train = pd.DataFrame(data)\n",
    "df_prev.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check difference between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING, Not all rows of original dataset are within new dataset.\u001b[0m\n",
      "IDs:\n",
      "         ID                                            passage\n",
      "4361  1016  Prior to the twentieth century Catholic priest...\n",
      "\u001b[93mIncluding unknown extra rows to new dataset, stop here if this is not desired.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Make sure all the rows in the original/previous dataset appear in the new one\n",
    "\n",
    "assert len(set(df_small.columns) - set(df_small.columns)) == 0, \"Dataframe columns do not match\"\n",
    "diff_count = len(df_small) - len(df_prev)\n",
    "# df_small['ID'].isin(df_prev['ID'])\n",
    "\n",
    "dif_df = df_prev[~df_prev['ID'].isin(df_small['ID'])] #get all ID's which are in the original dataset but not the new one\n",
    "if len(dif_df) != 0:\n",
    "    print('\\033[93m'+ \"WARNING, Not all rows of original dataset are within new dataset.\" + '\\033[0m')\n",
    "    print(\"IDs:\\n\",dif_df[['ID','passage']])\n",
    "    print('\\033[93m'+ \"Including unknown extra rows to new dataset, stop here if this is not desired.\" + '\\033[0m')\n",
    "    df_small = pd.concat([df_small, dif_df])\n",
    "    diff_count = len(df_small) - len(df_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m df_new \u001b[38;5;241m=\u001b[39m df_small[\u001b[38;5;241m~\u001b[39mdf_small[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(df_prev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Divide them and turn them into HRAF\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# create train and validation/test sets\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_val, test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # do it again to get the test and validation sets (15% = 50% * 30%)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# test, validation = train_test_split(test_val, test_size=0.5, random_state=10)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create an NLP friendly dataset\u001b[39;00m\n\u001b[1;32m     15\u001b[0m Hraf \u001b[38;5;241m=\u001b[39m DatasetDict(\n\u001b[1;32m     16\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(train_val\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     17\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(test\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m'\u001b[39m))})\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2240\u001b[0m     )\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# extract only the new rows which do not appear in the original dataset\n",
    "df_new = df_small[~df_small['ID'].isin(df_prev['ID'])]\n",
    "\n",
    "\n",
    "# Divide them and turn them into HRAF\n",
    "# create train and validation/test sets\n",
    "train_val, test = train_test_split(df_new, test_size=0.2, random_state=10)\n",
    "# # do it again to get the test and validation sets (15% = 50% * 30%)\n",
    "# test, validation = train_test_split(test_val, test_size=0.5, random_state=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an NLP friendly dataset\n",
    "Hraf = DatasetDict(\n",
    "    {'train':Dataset.from_dict(train_val.to_dict(orient= 'list')),\n",
    "     'test':Dataset.from_dict(test.to_dict(orient= 'list'))})\n",
    "Hraf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct filtering much like original training (copied and pasted or ran above cells when they are functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'EVENT', 1: 'CAUSE', 2: 'ACTION'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get labels\n",
    "labels = [label for label in Hraf['train'].features.keys() if label not in ['ID', 'passage']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# CHANGE Model name\n",
    "model = \"MultiLabel_ThreeLargeClasses_kfoldsDEMO\"\n",
    "\n",
    "# set up the pipeline from local\n",
    "import os\n",
    "path =os.path.abspath(f\"HRAF_Model_{model}\")\n",
    "# classifier = pipeline(\"text-classification\", model=path, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daea9b83f1ca4859b3534f39fcc59033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2937 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c486c5cb7444e5fa6c31ae515cc0a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2937\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 735\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tokenizer from old model\n",
    "model = \"MultiLabel_ThreeLargeClasses_kfoldsDEMO\"\n",
    "# set up the pipeline from local\n",
    "import os\n",
    "path =os.path.abspath(f\"HRAF_Model_{model}\") #the need to specify checkpoints may not be needed now with setting the load best checkpoint at the end, regardless, consider specifying\n",
    "# Note for above, the last accurate model was checkpoint-1176 so consider adding that into the path if you want to assure it uses it. Although I believe it should automatically load the best model!\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "\n",
    "# Tokenize data, remove all columns and give new ones (GET FUNCTION FROM ABOVE)\n",
    "tokenized_Hraf = Hraf.map(preprocess_data, batched=True, remove_columns=Hraf['train'].column_names)\n",
    "tokenized_Hraf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT:  0.5755640698169434\n",
      "CAUSE:  0.3959131545338442\n",
      "ACTION: 0.4108131119625372\n",
      "\n",
      "EVENT:  0.5683269476372924\n",
      "CAUSE:  0.3818646232439336\n",
      "ACTION: 0.4108131119625372\n",
      "\n",
      "EVENT:  0.5702127659574469\n",
      "CAUSE:  0.38382978723404254\n",
      "ACTION: 0.41106382978723405\n",
      "\n",
      "EVENT:  0.574468085106383\n",
      "CAUSE:  0.3880851063829787\n",
      "ACTION: 0.41106382978723405\n",
      "\n",
      "EVENT:  0.5714893617021276\n",
      "CAUSE:  0.38765957446808513\n",
      "ACTION: 0.41106382978723405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Splitting\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# folds = StratifiedKFold(n_splits=5)\n",
    "folds = StratifiedKFold(n_splits=5, shuffle= True, random_state=10)\n",
    "splits = folds.split(np.zeros(Hraf['train'].num_rows), Hraf['train']['ACTION'])\n",
    "\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "for train_idxs, val_idxs in splits:\n",
    "    train_list += [train_idxs]\n",
    "    val_list += [val_idxs]\n",
    "    print(f\"EVENT:  {np.mean(Hraf['train'][train_idxs]['EVENT'])}\\nCAUSE:  {np.mean(Hraf['train'][train_idxs]['CAUSE'])}\\nACTION: {np.mean(Hraf['train'][train_idxs]['ACTION'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate and create torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# Pad data\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# set to torch\n",
    "tokenized_Hraf.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model then Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"/Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"EVENT\",\n",
      "    \"1\": \"CAUSE\",\n",
      "    \"2\": \"ACTION\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"ACTION\": 2,\n",
      "    \"CAUSE\": 1,\n",
      "    \"EVENT\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-434.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    path, \n",
    "    problem_type='multi_label_classification',\n",
    "    num_labels = len(labels), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you run the functions above like the \"evaluate\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional Paramters\n",
    "\n",
    "### OPTIONAL If it crashes on a fold, you may skip the fold by specifying the start.\n",
    "### Set to 1 after a successful run\n",
    "start_fold = 1\n",
    "# # Set it to true if you want the model to start from a checkpoint, \n",
    "# # You can also specify a specific checkpoint. Otherwise choose False, normally, this may be good to set False unless a crash occurs\n",
    "resume_bool = False\n",
    "#set True if you want to start at the beginnning\n",
    "overwrite_training = False \n",
    "\n",
    "\n",
    "# Create Eval_dataset (be aware this may raise a prompt you must fill in)\n",
    "# only create a new eval_df if one does not exist (this step is useful in case of a crash)\n",
    "if 'eval_df' not in locals(): \n",
    "    eval_df = pd.DataFrame()\n",
    "else:\n",
    "    eval_inputAppend = input(\"eval_df found, would you like to append to there? (y/n)\")\n",
    "    if eval_inputAppend.lower() =='y':\n",
    "        print(\"Appending to old eval dataframe, this is useful if you must restart training\")\n",
    "        # fix issues with starting fold\n",
    "        if max(eval_df['fold']) >= start_fold: \n",
    "            Start_fold_input = input(f\"Your starting fold ({start_fold}) is not greater than the largest fold in the eval_df ({max(eval_df['fold'])}), this may mean redoing folds. Is this what you want (y/n)\")\n",
    "            if Start_fold_input.lower() != 'y':\n",
    "                raise Exception('Quitting run, please redo your start_fold parameter')\n",
    "    else:\n",
    "        eval_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2349\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1470\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 1--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8155b0376f9f4e1fb448ade42734158c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9cf619464e4c6f8704a5eb48f973a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3263649344444275, 'eval_f1': 0.8439450686641699, 'eval_roc_auc': 0.8593965908320601, 'eval_accuracy': 0.685374149659864, 'eval_runtime': 119.4519, 'eval_samples_per_second': 4.922, 'eval_steps_per_second': 0.619, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4052, 'learning_rate': 1.3197278911564626e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb8a5291d8b4950b77b9c4c0f667c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37282049655914307, 'eval_f1': 0.847457627118644, 'eval_roc_auc': 0.8628107124420551, 'eval_accuracy': 0.6972789115646258, 'eval_runtime': 119.6105, 'eval_samples_per_second': 4.916, 'eval_steps_per_second': 0.619, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c8e233bc2541a0a1ef338926e0be08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.514999508857727, 'eval_f1': 0.8489028213166143, 'eval_roc_auc': 0.864096059485757, 'eval_accuracy': 0.6989795918367347, 'eval_runtime': 118.9022, 'eval_samples_per_second': 4.945, 'eval_steps_per_second': 0.622, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1277, 'learning_rate': 6.394557823129253e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e866a7608874fbaaa2078c3f69c895e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6913695335388184, 'eval_f1': 0.8412291933418694, 'eval_roc_auc': 0.8578348811379884, 'eval_accuracy': 0.685374149659864, 'eval_runtime': 118.494, 'eval_samples_per_second': 4.962, 'eval_steps_per_second': 0.625, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba516468c08642c58ff55f6f647b4321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.757633626461029, 'eval_f1': 0.8413098236775819, 'eval_roc_auc': 0.8572977990061373, 'eval_accuracy': 0.6870748299319728, 'eval_runtime': 118.8199, 'eval_samples_per_second': 4.949, 'eval_steps_per_second': 0.623, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882 (score: 0.8489028213166143).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8431.8808, 'train_samples_per_second': 1.393, 'train_steps_per_second': 0.174, 'train_loss': 0.1985794482587957, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8bbbc076994e659552a4b24ff81306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2349\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1470\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 2--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb63489c6b7146c9afa05de7a6a064cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60f7316d947437d81cc836b86c8629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08184368908405304, 'eval_f1': 0.9680094786729859, 'eval_roc_auc': 0.9703874024526199, 'eval_accuracy': 0.9183673469387755, 'eval_runtime': 108.1964, 'eval_samples_per_second': 5.435, 'eval_steps_per_second': 0.684, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1517, 'learning_rate': 1.3197278911564626e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e180840ead54543b142d1e6ac3c7809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10213024169206619, 'eval_f1': 0.9692307692307691, 'eval_roc_auc': 0.9715951319212188, 'eval_accuracy': 0.923469387755102, 'eval_runtime': 107.9429, 'eval_samples_per_second': 5.447, 'eval_steps_per_second': 0.686, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ffbd91838442198195e49c242b9cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09630405902862549, 'eval_f1': 0.9695158398087268, 'eval_roc_auc': 0.9715719063545151, 'eval_accuracy': 0.9251700680272109, 'eval_runtime': 107.929, 'eval_samples_per_second': 5.448, 'eval_steps_per_second': 0.686, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0558, 'learning_rate': 6.394557823129253e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acbac3980334517b55ef1833c2fdc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10796252638101578, 'eval_f1': 0.9682063587282543, 'eval_roc_auc': 0.9702248234856932, 'eval_accuracy': 0.9251700680272109, 'eval_runtime': 107.8884, 'eval_samples_per_second': 5.45, 'eval_steps_per_second': 0.686, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3035fedb594142a38eb72d93ade713dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13214153051376343, 'eval_f1': 0.9663716814159292, 'eval_roc_auc': 0.9689241917502787, 'eval_accuracy': 0.9166666666666666, 'eval_runtime': 107.9752, 'eval_samples_per_second': 5.446, 'eval_steps_per_second': 0.685, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882 (score: 0.9695158398087268).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 588\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8278.3771, 'train_samples_per_second': 1.419, 'train_steps_per_second': 0.178, 'train_loss': 0.07752862722695279, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa4ba6140de4a65901d40e2400ea5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2350\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1470\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 3--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844c70e0516742b2837ed62ef9f5daaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0879d24edcbe4fa58a169a35198a058f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.006697264965623617, 'eval_f1': 0.9993876301285977, 'eval_roc_auc': 0.9993880048959609, 'eval_accuracy': 0.9982964224872232, 'eval_runtime': 116.2527, 'eval_samples_per_second': 5.049, 'eval_steps_per_second': 0.637, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0698, 'learning_rate': 1.3197278911564626e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc15493fef64317839574cab50f99b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013444957323372364, 'eval_f1': 0.9945155393053016, 'eval_roc_auc': 0.9951507167603677, 'eval_accuracy': 0.9846678023850085, 'eval_runtime': 115.7219, 'eval_samples_per_second': 5.073, 'eval_steps_per_second': 0.639, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c840363226745d3806b60e0832febcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012307526543736458, 'eval_f1': 0.9963325183374084, 'eval_roc_auc': 0.996657365724125, 'eval_accuracy': 0.989778534923339, 'eval_runtime': 117.4584, 'eval_samples_per_second': 4.998, 'eval_steps_per_second': 0.63, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0225, 'learning_rate': 6.394557823129253e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6817c251afbe49b5824bdc2ec19b9eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007532469928264618, 'eval_f1': 0.998165137614679, 'eval_roc_auc': 0.9983286828620626, 'eval_accuracy': 0.9948892674616695, 'eval_runtime': 116.3298, 'eval_samples_per_second': 5.046, 'eval_steps_per_second': 0.636, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2f4950ad6743c6b4d535a4997b41c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007237689569592476, 'eval_f1': 0.998165137614679, 'eval_roc_auc': 0.9983286828620626, 'eval_accuracy': 0.9948892674616695, 'eval_runtime': 116.2664, 'eval_samples_per_second': 5.049, 'eval_steps_per_second': 0.636, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294 (score: 0.9993876301285977).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8252.0489, 'train_samples_per_second': 1.424, 'train_steps_per_second': 0.178, 'train_loss': 0.03379697296895137, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfd164828b24b459f6941a34205ea32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2350\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1470\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 4--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19215a99990941bd87b365839ef36cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbd364d0865445bbfecf042cf8fd090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021204331889748573, 'eval_f1': 0.993734335839599, 'eval_roc_auc': 0.9943785565163971, 'eval_accuracy': 0.9846678023850085, 'eval_runtime': 111.6766, 'eval_samples_per_second': 5.256, 'eval_steps_per_second': 0.663, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0464, 'learning_rate': 1.3197278911564626e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcdc863b4de4999a53237a267d2be83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.027905471622943878, 'eval_f1': 0.9925093632958802, 'eval_roc_auc': 0.9935585728640077, 'eval_accuracy': 0.9812606473594548, 'eval_runtime': 111.5736, 'eval_samples_per_second': 5.261, 'eval_steps_per_second': 0.663, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b85583d21854aa6a363336c0ed4e634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03012479841709137, 'eval_f1': 0.9925187032418953, 'eval_roc_auc': 0.9936672532369831, 'eval_accuracy': 0.9812606473594548, 'eval_runtime': 111.3146, 'eval_samples_per_second': 5.273, 'eval_steps_per_second': 0.665, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.018, 'learning_rate': 6.394557823129253e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caf90a5f4c042ea972709ecf0f24eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02782345376908779, 'eval_f1': 0.9931378665003119, 'eval_roc_auc': 0.9941859254361534, 'eval_accuracy': 0.9829642248722317, 'eval_runtime': 112.199, 'eval_samples_per_second': 5.232, 'eval_steps_per_second': 0.66, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278804a1bd0a4860b1c2aac7de7dd44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.026869775727391243, 'eval_f1': 0.9950062421972534, 'eval_roc_auc': 0.995850622406639, 'eval_accuracy': 0.9880749574105622, 'eval_runtime': 110.7282, 'eval_samples_per_second': 5.301, 'eval_steps_per_second': 0.668, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470 (score: 0.9950062421972534).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8511.5823, 'train_samples_per_second': 1.38, 'train_steps_per_second': 0.173, 'train_loss': 0.02251990786215075, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df05c126d8104077a225312f5d3ece2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2350\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1470\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fold 5--------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd22b7161cd04f29a0a2c9bd602fbd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085d6cb850414856bc28a586b6d1c128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.009680557064712048, 'eval_f1': 0.9962871287128713, 'eval_roc_auc': 0.9968619246861924, 'eval_accuracy': 0.9931856899488927, 'eval_runtime': 117.0172, 'eval_samples_per_second': 5.016, 'eval_steps_per_second': 0.632, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-294/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0259, 'learning_rate': 1.3197278911564626e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331bf183e4c548be898ee560c2478e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0021150456741452217, 'eval_f1': 0.9987577639751553, 'eval_roc_auc': 0.9988558694352764, 'eval_accuracy': 0.9965928449744463, 'eval_runtime': 116.9366, 'eval_samples_per_second': 5.02, 'eval_steps_per_second': 0.633, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-588/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399bb2b39fa249bc8c4864bb0a182390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.001561467070132494, 'eval_f1': 0.9987593052109182, 'eval_roc_auc': 0.9989539748953975, 'eval_accuracy': 0.9965928449744463, 'eval_runtime': 117.1931, 'eval_samples_per_second': 5.009, 'eval_steps_per_second': 0.631, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-882/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0119, 'learning_rate': 6.394557823129253e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9e8dc8ca97441e8405a691233f0519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0005287817912176251, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 117.9743, 'eval_samples_per_second': 4.976, 'eval_steps_per_second': 0.627, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c043232782b640e7ab22fdd3d3d7fced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002490115584805608, 'eval_f1': 1.0, 'eval_roc_auc': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 116.6999, 'eval_samples_per_second': 5.03, 'eval_steps_per_second': 0.634, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1470/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/checkpoint-1176 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 587\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8330.8436, 'train_samples_per_second': 1.41, 'train_steps_per_second': 0.176, 'train_loss': 0.013535653085124735, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf92be120a940abb27dbe0f867f9ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO\n",
      "Configuration saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/config.json\n",
      "Model weights saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/pytorch_model.bin\n",
      "tokenizer config file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/tokenizer_config.json\n",
      "Special tokens file saved in HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"HRAF_Model_MultiLabel_ThreeLargeClasses_kfoldsDEMO\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "assert (start_fold >0) and (start_fold <= len(train_list)), f\"Incorrect Starting fold, must be greater than or equal to 1 and less than or equal to {len(train_list)}\"\n",
    "for fold, (train_idxs, val_idxs) in enumerate(zip(train_list, val_list), start=1): # K-fold loop\n",
    "    \n",
    "    #Skip folds if desired\n",
    "    if start_fold >fold:\n",
    "        print('\\033[93m'+ f\"Skipping Fold {fold}\"+ '\\033[0m')\n",
    "        continue\n",
    "\n",
    "    print(f\"------Fold {fold}--------\\n\")\n",
    "    train_ds = tokenized_Hraf[\"train\"].select(train_idxs)\n",
    "    val_ds = tokenized_Hraf[\"train\"].select(val_idxs)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        \n",
    "    )\n",
    "    try:\n",
    "        trainer.train() \n",
    "    except:\n",
    "        print('\\033[93m'+ f\"A crash occurred, restarting fold from checkpoint\"+ '\\033[0m')\n",
    "        trainer.train(resume_from_checkpoint=True) #This is the same thing above but often restarting can make all the difference so let's try it\n",
    "\n",
    "    # Evaluate and then concatinate results to a dataframe\n",
    "    eval_dict = trainer.evaluate()\n",
    "    eval_df_line = pd.DataFrame([eval_dict])\n",
    "    eval_df_line[\"fold\"] = fold\n",
    "    eval_df_line[\"train_count\"] = len(train_ds)\n",
    "    eval_df_line[\"val_count\"] = len(val_ds)\n",
    "    eval_df_line[\"total_count\"] = eval_df_line[\"val_count\"] + eval_df_line[\"train_count\"]\n",
    "    eval_df = pd.concat([eval_df, eval_df_line])\n",
    "\n",
    "\n",
    "\n",
    "# Save the model to disk\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_loop(train_list=train_list, val_list=val_list, model=model, training_args=training_args, tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics, start_fold=1):\n",
    "#     assert (start_fold >0) and (start_fold <= len(train_list)), f\"Incorrect Starting fold, must be no lower than 1 and no higher than {len(train_list)}\"\n",
    "\n",
    "# train_loop(start_fold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_df = eval_df.drop(columns=['train_Count','val_Count',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Train_status</th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_roc_auc</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_count</th>\n",
       "      <th>val_count</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/04/04</td>\n",
       "      <td>Continue Training</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.848903</td>\n",
       "      <td>0.864096</td>\n",
       "      <td>0.698980</td>\n",
       "      <td>119.5624</td>\n",
       "      <td>4.918</td>\n",
       "      <td>0.619</td>\n",
       "      <td>2349</td>\n",
       "      <td>588</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/04/04</td>\n",
       "      <td>Continue Training</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.096304</td>\n",
       "      <td>0.969516</td>\n",
       "      <td>0.971572</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>108.4121</td>\n",
       "      <td>5.424</td>\n",
       "      <td>0.683</td>\n",
       "      <td>2349</td>\n",
       "      <td>588</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24/04/04</td>\n",
       "      <td>Continue Training</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.998296</td>\n",
       "      <td>116.6438</td>\n",
       "      <td>5.032</td>\n",
       "      <td>0.634</td>\n",
       "      <td>2350</td>\n",
       "      <td>587</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/04/04</td>\n",
       "      <td>Continue Training</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.026870</td>\n",
       "      <td>0.995006</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.988075</td>\n",
       "      <td>112.1460</td>\n",
       "      <td>5.234</td>\n",
       "      <td>0.660</td>\n",
       "      <td>2350</td>\n",
       "      <td>587</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24/04/04</td>\n",
       "      <td>Continue Training</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118.3625</td>\n",
       "      <td>4.959</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2350</td>\n",
       "      <td>587</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date       Train_status  fold  epoch  eval_loss   eval_f1   \n",
       "0  24/04/04  Continue Training     1    5.0   0.515000  0.848903  \\\n",
       "1  24/04/04  Continue Training     2    5.0   0.096304  0.969516   \n",
       "2  24/04/04  Continue Training     3    5.0   0.006697  0.999388   \n",
       "3  24/04/04  Continue Training     4    5.0   0.026870  0.995006   \n",
       "4  24/04/04  Continue Training     5    5.0   0.000529  1.000000   \n",
       "\n",
       "   eval_roc_auc  eval_accuracy  eval_runtime  eval_samples_per_second   \n",
       "0      0.864096       0.698980      119.5624                    4.918  \\\n",
       "1      0.971572       0.925170      108.4121                    5.424   \n",
       "2      0.999388       0.998296      116.6438                    5.032   \n",
       "3      0.995851       0.988075      112.1460                    5.234   \n",
       "4      1.000000       1.000000      118.3625                    4.959   \n",
       "\n",
       "   eval_steps_per_second  train_count  val_count  total_count  \n",
       "0                  0.619         2349        588         2937  \n",
       "1                  0.683         2349        588         2937  \n",
       "2                  0.634         2350        587         2937  \n",
       "3                  0.660         2350        587         2937  \n",
       "4                  0.625         2350        587         2937  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augment Evaluation File \n",
    "\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "date_tm = today.strftime(\"%y/%m/%d\")\n",
    "\n",
    "#reorganize columns\n",
    "cols = list(eval_df.columns.values) \n",
    "remove_list = [\"fold\", \"epoch\"]\n",
    "for removal in remove_list:\n",
    "    cols.remove(removal)\n",
    "cols = [\"fold\",\"epoch\"]+cols\n",
    "eval_df = eval_df[cols]\n",
    "\n",
    "numrows = sum(Hraf.num_rows.values())\n",
    "\n",
    "trainingStatus = 'Initial Training' if overwrite_training == True else 'Continue Training'\n",
    "\n",
    "info_df  = pd.DataFrame({\"Date\":len(eval_df)*[date_tm],\"Train_status\":len(eval_df)*[trainingStatus]})\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "eval_df = pd.concat([info_df, eval_df], axis=1)\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evalutaion if it exists\n",
    "if os.path.exists(\"Evaluation.xlsx\"):\n",
    "    old_eval = pd.read_excel(\"Evaluation.xlsx\", index_col=0)\n",
    "    eval_df = pd.concat([old_eval, eval_df])\n",
    "\n",
    "eval_df.to_excel('Evaluation.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Paritioned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7277 Rows for 'train' succesfully saved to /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/Datasets/train_dataset.json\n",
      "1820 Rows for 'test' succesfully saved to /Users/ericchantland/Library/CloudStorage/Dropbox/MEM-DEV-LAB-Current/2023-eHRAF-Misf/HRAF-Misf-NaturalLanguageProcessing/HRAF_NLP/HRAF_MultiLabel_ThreeLargeClasses_kfoldsDemo/Datasets/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "def make_dir(path):\n",
    "    import os\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "# make folder if it does not exist yet\n",
    "path = os.getcwd() + '/Datasets'\n",
    "make_dir(path)\n",
    "# save to Json\n",
    "for key in Hraf.keys():\n",
    "    Hraf_dict = Hraf[key]\n",
    "    Hraf_dict = concatenate_datasets([Hraf_dict, Hraf_prev[key]])\n",
    "    Hraf_dict = Hraf_dict.to_dict()\n",
    "    file_path = f\"{path}/{key}_dataset.json\"\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(Hraf_dict, outfile)\n",
    "        print(len(Hraf_dict['ID']), f\"Rows for \\'{key}\\' succesfully saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 2937\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 735\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 4340\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "        num_rows: 1085\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hraf_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'passage', 'EVENT', 'CAUSE', 'ACTION'],\n",
       "    num_rows: 7277\n",
       "})"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Hraf_dummy = Hraf['train']\n",
    "Hraf_dummy = concatenate_datasets([Hraf_dummy, Hraf_prev['train']])\n",
    "Hraf_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a list of Dataset objects or a list of IterableDataset objects, but first element is a <class 'datasets.dataset_dict.DatasetDict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[181], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Hraf_dummy \u001b[38;5;241m=\u001b[39m Hraf\n\u001b[0;32m----> 2\u001b[0m Hraf_dummy \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHraf_dummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHraf_prev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m Hraf_dummy\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NLP-3/lib/python3.10/site-packages/datasets/combine.py:178\u001b[0m, in \u001b[0;36mconcatenate_datasets\u001b[0;34m(dsets, info, split, axis)\u001b[0m\n\u001b[1;32m    176\u001b[0m map_style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(dsets[\u001b[38;5;241m0\u001b[39m], Dataset)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (iterable \u001b[38;5;241m^\u001b[39m map_style):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a list of Dataset objects or a list of IterableDataset objects, but first element is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dsets[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m dsets[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (map_style \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, Dataset)) \u001b[38;5;129;01mor\u001b[39;00m (iterable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, IterableDataset)):\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a list of Dataset objects or a list of IterableDataset objects, but first element is a <class 'datasets.dataset_dict.DatasetDict'>"
     ]
    }
   ],
   "source": [
    "Hraf_dummy = Hraf\n",
    "Hraf_dummy = concatenate_datasets([Hraf_dummy, Hraf_prev])\n",
    "Hraf_dummy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
